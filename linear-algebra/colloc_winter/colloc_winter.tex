\documentclass[a4paper, 12pt]{article}
\usepackage{cmap}           % Пакет для поиска в полученной пдфке
\usepackage[utf8]{inputenc} % Ззамена кодировки файла на utf8
\usepackage[T2A]{fontenc}   % Подключение кодировки шрифтов
\usepackage[russian]{babel} % Использование русского языка 
\usepackage[left=2cm, right=2cm, top=1cm, bottom=2cm]{geometry} % Изменение размеров полей
\usepackage{indentfirst}    % Красная строка в начале текста
\usepackage{amsmath, amsfonts, amsthm, mathtools, amssymb, icomma, units, yfonts}
\usepackage{amsthm} % Пакет для нормального оформления теорем
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{esvect}
\usepackage{epigraph}
\usetikzlibrary{calc,matrix}

% Различные операторы
\DeclareMathOperator{\Mat}{Mat}
\DeclareMathOperator{\Tr}{tr}
\DeclareMathOperator{\sgn}{sgn}
\DeclareMathOperator{\rk}{rk}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\diag}{diag}


\renewcommand{\qedsymbol}{\textbf{Q.E.D.}}

% Объявление теорем и лемм
\newtheorem*{lemma}{Лемма}
\newtheorem*{theorem}{Теорема} 
\newtheorem*{follows}{Следствие} 
\newtheorem*{suggestion}{Преложение}
\newtheorem*{note}{Замечание}
\newtheorem*{definition}{Определение}

\newtheorem*{triangle_inequality}{Неравенство треугольника}
\newtheorem*{T_multiplication}{Теорема}
\newtheorem*{cauchy_inequality}{Неравенство Коши}
\newtheorem*{zero_angle}{Теорема}
\newtheorem*{associativity_change}{Ассоциативность произведения подстановок}
\newtheorem*{T_det}{Теорема}
\newtheorem*{associativity}{Ассоциативность умножения}
\newtheorem*{linear_determinant}{Теорема о полилинейной кососимметрической функции строк (столбцов) матрицы} 
\newtheorem*{laplace_theorem}{Теорема Лапласа о разложении определителя по строке (столбцу)}
\newtheorem{base_44}{Предложение}
\newtheorem*{base_44-cons}{Следствие}
\newtheorem*{que22lemma1}{Лемма 1}
\newtheorem*{que22lemma2}{Лемма 2}
\newtheorem*{que22theorem}{Теорема}
\newtheorem*{que31theorem}{Теорема}
\newtheorem*{que49theorem}{Теорема о ранге матрицы}
\newtheorem*{fake-determinant}{Лемма о фальшивом разложении определителя}
\newtheorem*{proposal}{Предложение}
\newtheorem*{que33theorem}{Теорема}
\newtheorem*{que21prop}{Свойство}
\newtheorem*{linear}{Основная лемма о линейной зависимости}
\newtheorem*{que30theorem}{Теорема}
\newtheorem*{que30cons1}{Следствие 1}
\newtheorem*{que30cons2}{Следствие 2}
\newtheorem*{solutions}{Теорема о размерности пространства решений однородной системы линейных уравнений}
\newtheorem*{linear_manifold_1}{Теорема}
\newtheorem*{linear_manifold_2}{Теорема}
\newtheorem*{Kroneker}{Теорема Кронекера-Капелли}
\newtheorem*{que34theorem}{Теорема}
\newtheorem*{que24theorem}{Теорема о полилинейной кососимметрической функции строк}
\newtheorem*{que24cons}{Следствие (аксиоматическое определение определителя)}
\newtheorem*{que24lemma}{Лемма}
\newtheorem*{que33cons}{Следствие}
\newtheorem*{que47theorem1}{Теорема}
\newtheorem*{que47theorem2}{Теорема}
\newtheorem*{que47cons}{Лемма}
\newtheorem*{que49cons}{Следствие}
\newtheorem*{que52lemma1}{Лемма 1}
\newtheorem*{que52lemma2}{Лемма 2}
\newtheorem*{theorem46}{Теорема}
\newtheorem*{que40suggest}{Предложение}

%Команды
\newcommand{\bbR}[0]{\mathbb{R}}

\title{Линейная Алгебра и Геометрия}
\author{}
%\author{Клуб Альтруистичных, Инициативных и Находчивых: Беляков Денис \\Вельдяйкин Николай \\Гринберг Вадим\\ Иовлева Анастасия\\ Попов Никита \\Пузырев Дмитрий \\Сухова Ольга \\Хайдуров Руслан\\ Хачиянц Алексей}
\date{}

\begin{document}
\maketitle

%\vspace*{0.5cm}

%\begin{center}
%\Large{\textbf{Экзамен по Линейной Алгебре и Геометрии}}
%\end{center}

\begin{flushleft}
\textit{Клуб Альтруистичных, Инициативных и Находчивых:}

\small{Беляков Денис \\Вельдяйкин Николай \\Гринберг Вадим\\ Иовлева Анастасия\\ Попов Никита \\Пузырев Дмитрий \\Сухова Ольга \\Хайдуров Руслан\\ Хачиянц Алексей}
\end{flushleft}

\epigraph{Надо просто сесть и \textit{постигнуть}.}
{Р.С. Авдеев}




% Не забываем указывать авторство. На всякий случай.
\section{Определения}
\begin{enumerate}
\item \textbf{Арифметический $n$-мерный вектор} — упорядоченный набор $n$ чисел:\\ $\vec{a} = (a_1, a_2, \ldots, a_n), a_i \in \mathbb{R}$, записанных в строку или столбец.
 
\item \textbf{Арифметическое $n$-мерное пространство} — множество всех арифметических $n$-мерных векторов; $\mathbb{R}^n$.

\item \textbf{Сумма двух арифметических $n$-мерных векторов} — $\vec a + \vec b = (a_1 + b_1, \dots, a_n+b_n)$.

\item \textbf{Умножение арифметического $n$-мерного вектора на скаляр} --- \\$k\vec a = (ka_1, \ldots, ka_n)$.

\item \textbf{Длина арифметического $n$-мерного вектора} — $|\vec x| = \sqrt{\langle \vec{x}, \vec{x} \rangle}$ (\textit{прим.:} cкалярное умножение: $\langle \vec{x}, \vec{y} \rangle = \sum\limits_{i = 1}^{n} x_i\cdot y_i$).

\item \textbf{Угол между двумя арифметическими $n$-мерными векторами} — \[\alpha = \arccos \frac{\langle \vec{x}, \vec{y} \rangle}{|\vec x||\vec y|}\]

\item \textbf{Линейная функция} — $f: \mathbb{R}^n \rightarrow \mathbb{R}, f(x_1, \ldots, x_n) = a_1x_1 + \dots + a_nx_n$.

\item \textbf{Линейное уравнение} — $a_1x_1 + \ldots + a_nx_n = b$, где $x_i$ — неизвестные. При $b = 0$ уравнение называют \textit{однородным}.

\item \textbf{Линейное многообразие} — множество решений в $\mathbb{R}^n$ системы линейных уравнений.

\item \textbf{Сумма двух матриц} — $A + B = (a_{ij} + b_{ij})$.

\item \textbf{Умножение матрицы на скаляр} — $kA = (ka_{ij})$.

\item \textbf{Транспонированная матрица} — $A^T = (a_{ji})$.

\item \textbf{Произведение двух матриц} — $A \in \Mat_{m\times n},\ B \in \Mat_{n \times l},\ AB \in \Mat_{m \times l}$ 
$$
(AB)_{ij}= \sum_{k = 1}^{n}a_{ik}b_{kj}
$$

\item \textbf{Диагональная матрица} —$a_{ij} = 0$ при $i \ne j$; обозначение: $\diag(a_1, a_2, \ldots, a_n)$. 

\item \textbf{Единичная матрица} — $E = \diag(1, 1, \ldots, 1)$.

\item \textbf{След квадратной матрицы} — $\Tr A = \sum\limits_{i = 1}^{n} a_{ii}$.

\item \textbf{Совместная система линейных уравнений} — есть хотя бы одно решение.

\item \textbf{Несовместная система линейных уравнений} — нет ни одного решения.

\item \textbf{Определенная система линейных уравнений} — единственное решение.

\item \textbf{Неопределенная система линейных уравнений} — более одного решения или решений нет.

\item \textbf{Определитель квадратной матрицы второго порядка} — $\det{A} = a_{11}a_{22} - a_{12} a_{21}$.

\item \textbf{Определитель квадратной матрицы третьего порядка} — $\det{A} = a_{11} a_{22} a_{33} + a_{12} a_{23} a_{31} + a_{13} a_{21} a_{32} - a_{13} a_{22} a_{31} - a_{12} a_{21} a_{33} - a_{11} a_{23} a_{32}$.

\item \textbf{Перестановка элементов множества $\{1,2,\dots,n\}$} — всякий упорядоченный набор из $n$ элементов $\{1, 2, \dots, n\}$, в котором каждый элемент встречается ровно один раз.

\item \textbf{Подстановка элементов множества $\{1, 2, \dots, n\}$} — всякое биективное отображение этого множества в себя; биективная функция, сопоставляющая набору чисел его перестановку.

\item \textbf{Инверсия в подстановке из $n$ элементов} — $i < j,$ но $\sigma(i) > \sigma(j)$.

\item \textbf{Знак подстановки} — $\sgn(\sigma) = (-1)^{N(\sigma)}$, где $N(\sigma)$ --- число инверсий в $\sigma$.

\item \textbf{Четная подстановка} — $\sgn (\sigma) = 1$ (или подстановка, имеющая чётное число инверсий).

\item \textbf{Нечетная подстановка} — $\sgn(\sigma) = -1$ (или подстановка, имеющая нечётное число инверсий).

\item \textbf{Произведение подстановок} — оно же \textbf{композиция}; $(\sigma\rho)(x) = \rho(\sigma(x))$. \\
\textsc{Примечание:} именно такой порядок был введен на лекциях, несмотря на то, что написано в Винберге, Куроше, Википедии и прочем. Связано это с тем, что в задачнике Проскурякова именно такой порядок.

\item \textbf{Тождественная подстановка} — $\id(x) = x,\ \  \forall x$.

\item \textbf{Обратная подстановка} — $\sigma^{-1}:\  \sigma \cdot \sigma^{-1} = \sigma^{-1} \cdot \sigma = \id$.

\item \textbf{Транспозиция} — $\tau_{ij}:\ \tau_{ij}(i) = j,\ \tau_{ij}(j) = i,\ \tau_{ij}(x) = x, \ x \not= i, j$

\item \textbf{Элементарная транспозиция} — $\tau_{i, i+1}$.

\item \textbf{Общая формула для определителя квадратной матрицы произвольного порядка} — $\det{A} = \sum\limits_{\sigma \in S_n} \text{sgn}(\sigma)a_{1\sigma(1)}a_{2\sigma(2)}\ldots a_{n\sigma(n)}$, где $S_n$ --- множество подстановок.

\item \textbf{Верхнетреугольная матрица} — $a_{ij} = 0$, при $i > j$.


\item \textbf{Нижнетреугольная матрица} — $a_{ij} = 0$, при $i < j$.

\item \textbf{Кососимметрическая функция от нескольких аргументов} ---\\ $f(x_{\tau(1)}, x_{\tau(2)}, \dots, x_{\tau(n)}) = -f(x_1, x_2, \dots, x_n)\ \forall \tau$, где $\tau$ — транспозиция в $S_n$. Иными словами, функция меняет знак при перестановке любых двух аргументов.

\item \textbf{Полилинейная функция от нескольких аргументов} — для каждого аргумента выполняется, что:
\begin{enumerate}
\item $f(\ldots, \lambda x_i, \dots) = \lambda f(\dots, x_i, \dots)$;
\item $f(\ldots, x_i' + x_i'', \dots) = f(\dots, x_i', \dots) + f(\dots, x_i'', \dots)$.
\end{enumerate}

\item \textbf{Дополнительный минор к элементу квадратной матрицы} --- $\overline{M}_{ij} = \det{A'}$, для $A'$, полученной из $A$ «вычеркиванием» $i$-ой строки и $j$-ого столбца.

\item \textbf{Алгебраическое дополнение к элементу квадратной матрицы} --- \\$A_{ij} = (-1)^{i+j} \overline{M}_{ij}$.

\item \textbf{Обратная матрица} — $A^{-1}:\ A\cdot A^{-1} = A^{-1} \cdot A = E$.

\item \textbf{Присоединенная матрица} — $\hat{A} = (A_{ij})^T$.

\item \textbf{Элементарные преобразования строк матрицы} — 
\begin{enumerate}
\item $\text{Э}_1(i, j, \lambda):\ A_{(i)} \rightsquigarrow A_{(i)} + \lambda A_{(j)}$ (прибавление к $i$-й строке $j$-й строки, домноженной на коэффициент $\lambda$);

\item $\text{Э}_2(i, j):\ A_{(i)} \leftrightsquigarrow A_{(j)}$ (перестановка $i$-й и $j$-й строк);

\item $\text{Э}_3(i, \lambda):\ A_{(i)} \rightsquigarrow \lambda A_{(i)}$ (умножение $i$-й строки на коэффициент $\lambda$).
\end{enumerate}

\item \textbf{Ступенчатый вид матрицы} — 
\begin{enumerate}
\item номера ведущих элементов (\textit{прим.:} первый ненулевой элемент) строк строго возрастают;

\item все нулевые строки стоят в конце (внизу).
\end{enumerate}

\item \textbf{Улучшенный ступенчатый вид матрицы}, он же \textbf{канонический} 
\begin{enumerate}
\item имеет ступенчатый вид;
\item все ведущие элементы строк равны 1, и во всех столбцах, содержащих ведущие элементы, над ведущими элементами стоят нули.
\end{enumerate}

\item \textbf{Расширенная матрица системы линейных уравнений} — $(A \mid \vec b)$, где $A$ — матрица коэффициентов, а $\vec b$ — вектор правых частей.

\item \textbf{Эквивалентные системы линейных уравнений} — имеют одинаковые множества решений.

\item \textbf{Однородная система линейных уравнений} — $A \vec x = \vec 0$.

\item \textbf{Векторное пространство} — также \textbf{линейное}; множество $V$ (над полем $\mathbb{R}$), в котором заданы следующие операции:
\begin{enumerate}
\item «сложение»: $V \times V \rightarrow V: (\vec{a}, \vec{b}) \mapsto (\vec{a}+\vec{b})$;

\item «умножение на скаляр»: $\mathbb{R} \times V \rightarrow V: (\lambda, \vec{a}) \mapsto \lambda \cdot \vec{a}$.
\end{enumerate}
Аксиомы векторного пространства:
\begin{enumerate}
\item $\vec{a}+\vec{b} = \vec{b}+\vec{a}$ --- коммутативность;

\item $(\vec{a}+\vec{b}) + \vec{c} = \vec{a} + (\vec{b} + \vec{c})$ --- ассоциативность;

\item $\exists \vec0 \in V:\ \vec{a} + \vec0 = \vec0 + \vec{a} = \vec{a}$ --- существование нулевого элемента;

\item $\exists (-\vec{a}):\ (-\vec{a}) + \vec{a} = \vec{a} + (-\vec{a}) = \vec{0}$ --- существование обратного элемента;

\item $1 \cdot \vec{a} = \vec{a}$ --- умножение на единичный скаляр;

\item $(\lambda \mu)\vec{a} = \lambda(\mu \vec{a})$ --- ассоциативность умножения на скаляр;

\item $(\lambda + \mu)\vec{a} = \lambda \vec{a} + \mu \vec{a}$ --- дистрибутивность умножения на скаляр относительно сложения;

\item $\lambda(\vec{a} + \vec{b}) = \lambda \vec{a} + \lambda \vec{b}$ --- дистрибутивность сложения относительно умножения на скаляр.
\end{enumerate}

\item \textbf{Подпространство векторного пространства} — подмножество $U \subseteq V$, такое, что:
\begin{enumerate}
\item $\vec0 \in U$;
\item $\forall \vec{a}, \vec{b} \in U\; (\vec{a}+\vec{b}) \in U$;
\item $\forall \vec{a} \in U, \lambda \in \mathbb{R}\; \lambda \vec{a} \in U$.
\end{enumerate}

\item \textbf{Линейная комбинация конечного набора векторов векторного пространства} --- всякий вектор $\vec v =  a_1\vec{x_1} + \ldots + a_n\vec{x_n}, a_1, a_2, \ldots, a_n \in \mathbb{R}$. 

\item \textbf{Линейная оболочка подмножества векторного пространства} — множество всех линейных комбинаций векторов данного подмножества; $\langle S \rangle$.

\item \textbf{Конечномерное векторное пространство} — пространство порождается конечным количеством своих векторов; существует конечное подмножество $S$, что $\langle S \rangle=V$.

\item \textbf{Линейная зависимость конечного набора векторов} — для векторов $\vec{v_1}$, $\vec{v_2}$, $\ldots$, $\vec{v_n}$ существует ненулевой набор скаляров $\lambda_1, \ldots, \lambda_n$ такой, что $\lambda_1\vec{v_1} + \ldots + \lambda_n\vec{v_n} = \vec{0}$. То есть, существует нетривиальная линейная комбинация, равная нулю.

\item \textbf{Линейная независимость конечного набора векторов} — \begin{itemize}
\item для векторов $\vec{v_1}, \vec{v_2}, \ldots, \vec{v_n}$ не существует ненулевого набор скаляров $\lambda_1, \ldots, \lambda_n$ такой, что $\lambda_1\vec{v_1} + \ldots + \lambda_n\vec{v_n} = \vec{0}$.
\item Если для векторов $\vec{v_1}, \vec{v_2}, \ldots, \vec{v_n}$ и каких-то скаляров $\lambda_1, \ldots, \lambda_n$ выполняется $\lambda_1\vec{v_1} + \ldots + \lambda_n\vec{v_n} = \vec{0}$, то $\lambda_1 = \ldots = \lambda_n = 0$.
\end{itemize} То есть, существует только тривиальная линейная комбинация, равная нулю.

\item \textbf{Базис конечномерного векторного пространства} — система векторов $e_1, \ldots, e_n$, такая, что любой $\vec{v} \in V$ единственным образом представляется в виде линейной комбинации этих векторов: $\vec{v} = a_1 e_1 + \ldots + a_n e_n$.

\item \textbf{Размерность конечномерного векторного пространства} — число элементов любого базиса оного пространства; $\dim{V}$.

\item \textbf{Ранг системы векторов конечномерного векторного пространства} — наибольшее число векторов в линейно-независимой подсистеме $S'\subseteq S$ системы $S$; обозначается $\rk{S}$.

\item \textbf{Столбцовый ранг матрицы} — ранг системы векторов-стобцов.

\item \textbf{Строковый ранг матрицы} — столбцовый ранг $A^T$.

\item \textbf{Минор матрицы $A$} — определитель всякой её квадратной подматрицы (примечание: подматрица $A$ --- всякая матрица, полученная из $A$ путём вычёркивания каких-то строк и/или столбцов).

\item \textbf{Фундаментальная система решений однородной системы линейных уравнений} — всякий базис пространства решений этой системы.

\item \textbf{Ортогональное дополнение подмножества в $\mathbb{R}^n$} — \[S^\perp \mathrel{:=} \{\vec x \in \mathbb{R}^n \mid \langle \vec{x}, \vec{y} \rangle =0\; \forall \vec y \in S\}\] то есть множество $S^\perp$, состоящее из векторов $\vec x \in \mathbb{R}^n$, таких, что они ортогональны сразу всем векторам из $S$.

\end{enumerate}

\newpage
\section{Вопросы}
% 1 - Беляков Денис
\subsection{Арифметические $n$-мерные векторы. Арифметическое $n$-мер\-ное пространство. Сложение арифметических $n$-мерных векторов и умножение на скаляр. Свойства этих операций.}

Упорядоченная система $n$ чисел
\[\alpha = (a_1, a_2, \ldots, a_n),\ a_1, \ldots, a_n \in \mathbb{R}\]
записанных в строку или столбец, называется \textit{арифметическим $n$-мерным вектором}. 
Числа $a_i, i = 1, 2, \ldots, n$, будут называться \textit{компонентами} вектора $\alpha$.

\textit{Арифметическое $n$-мерное пространство} --- множество всех арифметических $n$-мерных векторов. Обозначение: $\mathbb{R}^n$

\vspace{0.5cm}
Операции в $\mathbb{R}^n$:

\begin{itemize}
\item Сложение $\mathbb{R}^n \times \mathbb{R}^n \mapsto \mathbb{R}^n$. Паре векторов $(\vec{x}, \vec{y})$ сложение сопоставляет вектор $\vec{x} + \vec{y}$, определяемый следующим образом:
\[\vec{x} + \vec{y} \mathrel{:=} 
\begin{pmatrix}
x_1 + y_1 \\
x_2 + y_2 \\
\vdots \\
x_n + y_n
\end{pmatrix}\]
\item Умножение на скаляр. $\mathbb{R} \times \mathbb{R}^n \mapsto \mathbb{R}^n : (\lambda, \vec{x}) \mapsto \lambda\vec{x}$
\[\lambda\vec{x} \mathrel{:=} \begin{pmatrix}
\lambda x_1\\
\lambda x_2\\
\vdots\\
\lambda x_n
\end{pmatrix}\]
\end{itemize}

Свойства сложения и умножения на скаляр:
\begin{enumerate}
\item $\forall \vec{x}, \vec{y} \in \mathbb{R}^n\;\; \vec{x} + \vec{y} = \vec{y} + \vec{x}$ --- коммутативность сложения.

\item $\forall\vec{x}, \vec{y}, \vec{z} \in \mathbb{R}^n\;\; (\vec{x} + \vec{y}) + \vec{z} = \vec{x} + (\vec{y} + \vec{z})$ --- ассоциативность сложения.

\item $\exists\ \vec{0} =
\begin{pmatrix}
0 \\ 0 \\ \vdots \\ 0
\end{pmatrix} : \forall\vec{x} \in \mathbb{R}^n\;\; \vec{0} + \vec{x} = \vec{x}$ --- существование нейтрального по сложению элемента.

\item $\forall\vec{x} \in \mathbb{R}^n\ \exists \ -\vec{x} =
\begin{pmatrix}
-x_1 \\ -x_2\\ \vdots\\ -x_n
\end{pmatrix} : \vec{x} + (-\vec{x}) = \vec{0}$ --- существование противоположного элемента.

\item $\forall \alpha \in \mathbb{R}, \forall \vec{x} \in \mathbb{R}^n\;\; \alpha\vec{x} = \vec{x}\alpha$ --- коммутативность умножения на скаляр.

\item $\forall \alpha, \beta \in \mathbb{R}, \forall \vec{x} \in \mathbb{R}^n\;\; (\alpha\beta)\vec{x} = \alpha(\beta\vec{x})$ --- ассоциативность умножения на скаляр.

\item $\forall \vec{x} \in \mathbb{R}^n\;\; 1\vec{x} = \vec{x}$ --- существование нейтрального по умножению элемента.

\item $\forall \alpha, \beta \in \mathbb{R}, \forall \vec{x} \in \mathbb{R}^n\;\; (\alpha + \beta)\vec{x} = \alpha\vec{x} + \beta\vec{x}$ --- дистрибутивность умножения по сложению.

\item $\forall \alpha \in \mathbb{R}, \forall \vec{x}, \vec{y} \in \mathbb{R}\;\; \alpha(\vec{x} + \vec{y}) = \alpha\vec{x} + \alpha\vec{y}$ --- дистрибутивность сложения по умножению.

\item $\forall \vec{x} \in \mathbb{R}\;\;  0 \cdot \vec{x} = \vec0$ --- умножение на нулевой скаляр.

\item  $\forall \vec{x} \in \mathbb{R}\;\; -1 \cdot \vec{x} = -\vec{x}$ --- умножение на минус-единичный скаляр.

\item $\forall \alpha \in \mathbb{R}\;\; \alpha \cdot \vec{0} = \vec{0}$ --- умножение скаляра на нулевой вектор.

\item $\forall \alpha \in \mathbb{R}, \forall \vec{x} \in \mathbb{R}\;\; : \alpha \vec{x} = 0, \Rightarrow \alpha = 0 \vee \vec{x} = 0$ --- нулевое произведение.
\end{enumerate}


% 2 - Вельдяйкин Николай
\subsection{Скалярное произведение в арифметическом $n$-мерном про-\\странстве и его свойства. Длина арифметического $n$-мерного вектора.}
\textit{Скалярным произведением} двух векторов $\vec{x}, \vec{y} \in \bbR^n$ называется сумма произведений их координат:
\[\langle\vec{x}, \vec{y}\rangle = x_1y_1 + \ldots + x_ny_n = \sum_{i = 1}^{n} x_{i}y_{i}\]

\textit{Свойства скалярного произведения:}
\begin{enumerate}
\item Скалярное произведение нулевого вектора и любого другого равно нулю: \[\langle\vec{0}, \vec{x}\rangle = \langle\vec{x}, \vec{0}\rangle = \sum_{i = 1}^{n} 0 \cdot x_i = 0\]

\item Скалярное произведение коммутативно: \[\langle\vec{x}, \vec{y}\rangle = \sum_{i = 1}^{n} x_i y_i = \sum_{i = 1}^{n} y_i x_i = \langle\vec{y}, \vec{x}\rangle\]

\item Скалярное произведение дистрибутивно по сложению: \[\langle\vec{x} + \vec{y}, \vec{z}\rangle = \sum_{i = 1}^{n} (x_i + y_i) z_i = \sum_{i = 1}^{n} x_i z_i + \sum_{i = 1}^{n} y_i z_i = \langle\vec{x}, \vec{z}\rangle + \langle\vec{y}, \vec{z}\rangle\]

\item Скаляр можно внести внутрь скалярного произведения, причём его можно отнести к любому вектору:\[\alpha \langle\vec{x}, \vec{y}\rangle = \alpha \sum_{i = 1}^{n} x_i y_i = \sum_{i = 1}^{n} \alpha x_i y_i = \langle \alpha \vec{x}, \vec{y}\rangle = \langle\vec{x}, \alpha \vec{y}\rangle\]

\item Скалярное произведение вектора $\vec{x}$ с самим собой неотрицательно: \[\langle \vec{x}, \vec{x} \rangle = x_1^2 + \ldots + x_n^2 \geqslant 0\] причем $\langle\vec{x}, \vec{x}\rangle =  0 \iff \vec{x} = \vec{0}$
\end{enumerate}

\textit{Длиной вектора} называют корень скалярного призведения вектора с самим собой: \[|\vec{x}| = \sqrt{\langle\vec{x}, \vec{x}\rangle}\]
\textit{Свойство длины векторов:} $|\vec{x}| \geqslant 0$, причем $|\vec{x}| =  0 \iff \vec{x} = \vec{0}$

% 3 - Гринберг Вадим
\subsection{Неравенство Коши в арифметическом $n$-мерном пространстве. Угол между двумя арифметическими $n$-мерными векторами.}
\begin{cauchy_inequality}
Пусть существуют векторы $x$ и $y \in \mathbb{R}^n$, тогда выполнено следующее неравенство: $|\langle x, y\rangle| \leqslant |x||y|$. Другими словами, модуль скалярного произведения векторов не больше произведения их длин.
\end{cauchy_inequality}
\begin{proof}
Рассмотрим произвольное число $\lambda \in \mathbb{R}$ и рассмотрим вектор $\vec{z} = \lambda\vec{x} + \vec{y}$. Так как длина вектора не меньше 0, то
\[\langle \vec{z}, \vec{z} \rangle \geqslant 0 \Longleftrightarrow \lambda^2|\vec{x}|^2 + 2\lambda\langle \vec{x}, \vec{y} \rangle + |\vec{y}|^2 \geqslant 0\]

Так как это верно для любого $\lambda \in \mathbb{R}$, то дискриминант квадратного уравнения относительно $\lambda$ не больше нуля. 

\[D: 4(\langle \vec{x}, \vec{y} \rangle)^2 - 4|\vec{x}|^2|\vec{y}|^2 \leqslant 0\]Тогда \[\langle \vec{x}, \vec{y} \rangle^2 \leqslant |\vec{x}|^2|\vec{y}|^2\text{ и }|\langle x, y\rangle| \leqslant |x||y|\].
\end{proof}
Пусть имеются два вектора $\vec{x}, \vec{y} \in \mathbb{R}^n$. Так как $|\langle x, y\rangle| \leqslant |x||y|$, то величина $\cfrac{\langle x, y\rangle}{|x||y|}$ лежит в пределах  $[-1, 1]$. Тогда можно ввести понятие \textit{угла $\alpha$ между векторами $x$ и $y$} следующим образом:
\[\alpha = \arccos \frac{\langle\vec{x}, \vec{y}\rangle} {|\vec{x}||\vec{y}|}\]

% 4 - Иовлева Анастасия
\subsection{Неравенство треугольника в арифметическом $n$-мерном пространстве.}
\begin{triangle_inequality}
Пусть векторы $\vec{x}, \vec{y}$ и $\vec{z}$ образуют треугольник в $n$-мерном пространстве. Докажем, что будет выполняться неравенство $|\vec{z}| \leqslant |\vec{x}| + |\vec{y}|$.
\end{triangle_inequality}
\begin{proof}
Заметим, что $\vec z = \vec{x} \pm \vec{y}$. Не умаляя общности, допустим, что направление векторов такое, что $\vec z = \vec x + \vec y$.  Вспомним также неравенство Коши: $|\langle \vec x, \vec y\rangle | \leqslant |\vec x||\vec y|$. Итого, получаем:
\begin{gather*}
|x + y|^2 = \langle x+y, x+y\rangle  = \langle x, x\rangle  + 2\langle x, y\rangle  + \langle y, y\rangle  \leqslant \\ \leqslant|x|^2 + |y|^2 + 2|x||y| = (|x| + |y|)^2 \\
\Downarrow \\
|x+y|\leqslant |x| + |y|
\end{gather*}
\end{proof}

% 5 - Попов Никита
\subsection{Линейные функции. Линейные уравнения. Линейные многообразия. Примеры.}
Линейная функция $f: \mathbb{R}^n \to \mathbb{R}$ — функция вида
\[f(x_1, x_2, \ldots, x_n)= a_1x_1 + a_2x_2 + \ldots + a_nx_n,\ a_1, a_2, \ldots, a_n \in \mathbb{R}\]

Примеры:
\begin{itemize}
    \item $f(x, y) = 2x-3y$ --- линейная;
    \item $f(x) = x - 5$ --- нелинейная;
    \item $f(x) = 0$ --- линейная;
    \item $f(x) = 1$ --- нелинейная;
\end{itemize}

\emph{Линейное уравнение} --- уравнение вида $a_1x_1 + a_2x_2 + \ldots + a_nx_n = b$

\emph{Линейное многообразие} --- множество решений в $\mathbb{R}^n$ системы линейных уравнений.

Примеры:
\begin{itemize}
    \item $ax+by=c$ 
    
    $\begin{pmatrix}
    \frac c a \\ 0
    \end{pmatrix} + \lambda
    \begin{pmatrix}
    1 \\ \frac b a
    \end{pmatrix}$ --- прямая в $\mathbb{R}^2$
    \item $ax+by+cz=d$ 
    %$\begin{pmatrix}
    %\frac d a \\ 0 \\ 0
    %\end{pmatrix} + \lambda
    %\begin{pmatrix}
    %1 \\ \frac b a \\ \frac c a
    %\end{pmatrix}$ 
    --- задаёт плоскость в $\mathbb{R}^3$
    \item $ 
        \begin{cases}
            a_1x+b_1y+c_1z=d_1\\
            a_2x+b_2y+c_2z=d_2
        \end{cases}$  --- задаёт прямую (пересечение двух плоскостей) в $\mathbb{R}^3$
\end{itemize}

% 6 - Пузырёв Дмитрий
\subsection{Матрицы. Сложение матриц, умножение на скаляр. Свойства этих операций.}
\textit{Матрица} размера $m \times n$ (или \textit{$m \times n$-матрица}) --- это прямоугольная таблица высоты $m$ и ширины $n$, в каждой клетке которой стоит один элемент.

Вообще говоря, матрицу можно задать (и она так задаётся в учебнике Куроша) как таблицу коэффициентов неизвестных при СЛУ, т.е. коэффициенты системы линейных уравнений
\[\begin{cases}
a_{11}x_1 + a_{12}x_2 + \ldots + a_{1n}x_n = b_1 \\
a_{21}x_1 + a_{22}x_2 + \ldots + a_{2n}x_n = b_2 \\
\dotfill \\
a_{m1}x_1 + a_{m2}x_2 + \ldots + a_{mn}x_n = b_m 
\end{cases}\]
задают матрицу
\[\begin{pmatrix}
a_{11} & a_{12} & \cdots & a_{1n} \\
a_{21} & a_{22} & \cdots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m1} & a_{m2} & \cdots & a_{mn}
\end{pmatrix}\]

\textit{Размером} матрицы называется количетво её строк и стоблцов. Говоря <<матрица размера $m \times n$>>, мы подразумеваем, что в матрице $m$ строк и $n$ столбцов. Это обозначается следующим образом: $A \in \Mat_{m \times n}$. Проводя аналогию со сказанным выше про СЛУ, можно сказать, что количество строк соответствует количеству уравнений в системе, а количество столбцов --- количеству неизвестных.

Матрица, у которой количество строк равно количеству столбцов (и равно $n$), называется квадратной порядка $n$.
Размер такой матрицы обозначается как $n \times n$. В таком случае пишут, что $A \in \mathrm{M}_n$

Отдельно рассмотрим матрицы $1 \times n$ и $m \times 1$. Они имеют специальные названия.
\begin{itemize}
\item Матрица размера $1 \times n$ называется \textit{вектор-строкой}
\[\begin{pmatrix}
a_1, a_2, \ldots ,a_n
\end{pmatrix}\]
\item Матрица размера $m \times 1$ называется \textit{вектор-столбцом}
\[\begin{pmatrix}
a_1 \\ a_2 \\ \vdots \\ a_m
\end{pmatrix}\]
\end{itemize}

Элемент матрицы имеет два индекса --- индекс строки и индекс столбца. Запись $a_{ij}$ означает, что мы рассматриваем элемент $i$-ой строки $j$-го столбца.

$\textit{Сложение}$ двух матриц определено только в том случае, когда размеры их одинаковы. $\textit{Суммой}$ двух матриц $A$ и $B$ размера $m \times n$ называется такая матрица $C$ размера $m \times n$, в которой каждый элемент равен сумме соответствующих элементов матриц $A$ и $B$, то есть
\[c_{ij} = a_{ij} + b_{ij}\]

Сложение матриц имеет следующие свойства, которые легко проверить по определению суммы:
\begin{enumerate}
\item $\forall A, B, C \in \Mat_{m \times n}\; (A + B) + C = A + (B + C)$ --- ассоциативность
\item $\forall A, B \in \Mat_{m \times n}\; A + B  = B + A$ --- коммутативность
\item $\exists\ 0 \in \Mat_{m \times n} : \forall A \in \Mat_{m \times n}\; A + 0 = 0 + A = A$ --- сложение с нулевой матрицей
\item $\forall A \in \Mat_{m \times n} \exists!(-A) = (-a_{ij}) : A + (-A) = (-A) + A = 0$ --- существование противоположной матрицы 
\end{enumerate}

\textit{Произведением} матрицы $A \in \Mat_{m \times n}$ на \textit{скаляр} $\lambda$ является такая матрица $B \in \Mat_{m \times n}$, в которой каждый элемент равен произведению соответствующего элемента матрицы $A$ и скаляра $\lambda$, то есть $(b_{ij}) = (\lambda a_{ij})$. Обозначение: $\lambda A$

Умножение матриц на скаляр имеет следующие свойства, которые легко проверить по определению:
\begin{enumerate}
\item $\forall A\in \Mat_{m \times n}\; 1 \cdot A = A$ --- умножение на единичный скаляр
\item $\forall \alpha, \beta \in \bbR, A\in \Mat_{m \times n}\;(\alpha\beta) A = \alpha(\beta A)$ --- ассоциативность
\item $\forall \alpha, \beta \in \bbR, A\in \Mat_{m \times n}\;(\alpha + \beta)A = \alpha A + \beta A$ --- дистрибутивность относительно скаляров
\item $\forall \lambda \in \bbR; A, B\in \Mat_{m \times n}\;\lambda (A + B) = \lambda A + \lambda B$ --- дистрибутивность относительно матриц
\end{enumerate}

Перечисленные выше свойства соответствуют аксиомам векторного пространства, поэтому совокупность матриц размера $m \times n$ можно рассматривать как $m \times n$-мерное векторное пространство.

% 7 - Сухова Ольга
\subsection{Произведение матриц: определение, дистрибутивность, связь с умножением на скаляр.}
$\textit{Произведением}$ матрицы A размера $m \times n$ и матрицы B размера $n \times l$ является матрица С размера $m \times l$, такая, что:
\[c_{ij} = A_{(i)} B^{(j)} = \sum\limits_{k = 1}^{n} a_{ik}b_{kj} = a_{i1} b_{1j} + a_{i2} b_{2j} + \ldots + a_{in} b_{nj}\]
Свойства произведения матриц: 
\begin{itemize}
\item Дистрибутивность: $A(B + C) = AB + AC$
\begin{proof}
Пусть $A \in \Mat_{m \times n}$, $B, C \in \Mat_{n \times k}$. Матрицы $A(B + C)$ и $AB + AC$ имеют одинаковый размер $m \times k$.

Пусть $D = A(B + C)$, $E = AB + AC$. Тогда
\[d_{ij}=\sum\limits_{s = 1}^{n} a_{is}(b_{sj} + c_{sj})= \sum\limits_{s=1}^{n} a_{is}b_{sj} + \sum\limits_{s = 1}^{n} a_{is}c_{sj}\]
\[e_{ij} = \sum\limits_{s = 1}^{n} a_{is}b_{sj} + \sum\limits_{s = 1}^{n} a_{is}c_{sj} = d_{ij}\]
Тогда $D = E \iff A(B + C) = AB + AC$.
\end{proof}

\item Дистрибутивность: $(B + C)A = BA + CA$ (доказательство аналогичное)

\item Произведение на скаляр: $\forall \lambda \in \mathbb{R}\; \lambda (AB) = (\lambda A)B = A(\lambda B)$
\end{itemize}

% 8 - Хайдуров Руслан
\subsection{Произведение матриц: ассоциативность, некоммутативность.}
\begin{associativity}
Пусть определено умножение произвольных матриц $A, B, C$ (то есть $A \in \Mat_{m\times l}, \ B\in \Mat_{l\times n},\ C \in \Mat_{n\times p}$). Тогда $(AB)C = A(BC)$.
\end{associativity}
\begin{proof} Пусть $AB = U$, $BC = V$ а $A(BC) = X$, $(AB)C = Y$. Тогда 
\begin{multline*}
y_{ij} = \sum_{k = 1}^{l} u_{ik}c_{kj} = \sum_{k = 1}^{l} \left(\sum_{r = 1}^{n} a_{ir} b_{rk}\right) c_{kj} = \sum_{k = 1}^{l} \sum_{r = 1}^{n} a_{ir} b_{rk} c_{kj} = \sum^n_{r=1} a_{ir} \left( \sum^l_{k=1} b_{rk} c_{kj} \right) = \\
= \sum^n_{r = 1} a_{ir} v_{rj} = x_{ij}
\end{multline*}
\end{proof}

В общем случае умножение матриц некоммутативно. Пример таких матриц:
\[\begin{pmatrix} 
0 & 1\\
0 & 0
\end{pmatrix}
\begin{pmatrix}
0 & 0 \\ 
1 & 0
\end{pmatrix} = 
\begin{pmatrix}
1 & 0\\
0 & 0
\end{pmatrix}
\neq
\begin{pmatrix}
0 & 0\\
0 & 1
\end{pmatrix} = 
\begin{pmatrix}
0 & 0 \\ 
1 & 0
\end{pmatrix}
\begin{pmatrix} 
0 & 1\\
0 & 0
\end{pmatrix}\]

% 9 - Хачиянц Алексей
\subsection{Транспонирование матриц: определение, связь со сложением и умножением на скаляр. Транспонирование произведения двух матриц.}
\textit{Транспонированием} матрицы называется преобразование матрицы такое, что столбцы становятся строками и наоборот. Это можно записать следующим образом: 
\[(a_{ij})^T = (a_{ji})\]
\textit{Связь транспонирования и умножения на скаляр:}
\[\lambda(a_{ij})^T = (\lambda a_{ji}) = (\lambda a_{ij})^T \Longleftrightarrow \lambda A^T = (\lambda A)^T\]
\textit{Связь транспонирования и сложения:}
\[(a_{ij})^T + (b_{ij})^T = (a_{ji} + b_{ji}) = (a_{ij} + b_{ij})^T \Longleftrightarrow A^T + B^T = (A + B)^T\]
Это рассуждение обобщается на произвольное количество матриц с помощью математической индукции.

\begin{T_multiplication}
Для любых $A \in \Mat_{n \times m}$, $B \in \Mat_{m \times p}$ верно:
$(AB)^T = B^T A^T$
\end{T_multiplication}
\begin{proof}
Сначала покажем совпадение размерностей произведений. Произведение матриц А и В будет иметь размерность $n \times p$. Тогда $(AB)^T$ имеет размер $p \times n$. Теперь проверим правую часть равенства. $B^T$ имеет размер $p \times m$, а $A^T$ имеет размер $m \times n$. Тогда их произведение будет иметь размер $p \times n$. Размерности совпадают.

Пусть $AB = C$, а $B^T A^T = D$. Тогда
\[d_{ij} = \sum_{k = 1}^{m} b_{ik}^Ta_{kj}^T = \sum_{k = 1}^{m} a_{jk}b_{ki} = c_{ji} = (c_{ij})^T\]
Тогда $D = C^T$ и $(AB)^T = B^T A^T$. С помощью математической индукции эти 2 рассуждения можно обобщить на $n$ матриц.
\end{proof}

% 10 - Беляков Денис
\subsection{Диагональные матрицы. Умножение на диагональную матрицу слева и справа. Единичная матрица и её свойства.}

\textit{Диагональной матрицей} называют квадратную матрицу, в которой элементы вне главной диагонали равны нулю. Обозначается $\diag(a_1, a_2, \ldots, a_n)$:

\[\mathrm{diag}(a_1, a_2, \ldots, a_n) = \begin{pmatrix}
a_1 & 0 & \cdots & 0 \\
0 & a_2 & \cdots & 0 \\         
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots  & a_n
\end{pmatrix}\]

\textbf{Свойство:} \textit{Пусть $A_1 = \mathrm{diag}(a_1, a_2, \dots, a_n)$,$A_2 = \mathrm{diag}(a_1, a_2, \dots, a_m)$, а $B \in \Mat_{n \times m}$. тогда:
\[A_1B = \begin{pmatrix}
a_1B_{(1)}\\
a_2B_{(2)}\\
\vdots\\
a_nB_{(n)}
\end{pmatrix},\;BA_2 = \begin{pmatrix}a_1B^{(1)}, a_2B^{(2)}, \ldots, a_nB^{(m)}\end{pmatrix}\]}
\begin{proof}
\begin{multline*}
A_1B =
\begin{pmatrix}
a_1 & 0 & \cdots & 0 \\
0 & a_2 & \cdots & 0 \\         
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots  & a_n
\end{pmatrix}
\begin{pmatrix}
b_{11} & b_{12} & \cdots & b_{1m} \\
b_{21} & b_{22} & \cdots & b_{2m} \\
\vdots & \vdots & \ddots & \vdots \\
b_{n1} & b_{n2} & \cdots & b_{nm}
\end{pmatrix} = \\
=
\begin{pmatrix}
a_1b_{11} & a_1b_{12} & \cdots & a_1b_{1m} \\
a_2b_{21} & a_2b_{22} & \cdots & a_2b_{2m} \\
\vdots & \vdots & \ddots & \vdots \\
a_nb_{n1} & a_nb_{n2} & \cdots & a_nb_{nm}
\end{pmatrix} = \begin{pmatrix}
a_1B_{(1)}\\
a_2B_{(2)}\\
\vdots\\
a_nB_{(n)}
\end{pmatrix}
\end{multline*}

\begin{multline*}
BA_2 = 
\begin{pmatrix}
b_{11} & b_{12} & \cdots & b_{1m} \\
b_{21} & b_{22} & \cdots & b_{2m} \\
\vdots & \vdots & \ddots & \vdots \\
b_{n1} & b_{n2} & \cdots & b_{nm}
\end{pmatrix}
\begin{pmatrix}
a_1 & 0 & \cdots & 0 \\
0 & a_2 & \cdots & 0 \\         
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots  & a_m
\end{pmatrix} = 
\begin{pmatrix}
a_1b_{11} & a_2b_{12} & \cdots & a_nb_{1m} \\
a_1b_{21} & a_2b_{22} & \cdots & a_nb_{2m} \\
\vdots & \vdots & \ddots & \vdots \\
a_1b_{n1} & a_2b_{n2} & \cdots & a_nb_{nm}
\end{pmatrix} = \\
= \begin{pmatrix}a_1B^{(1)}, a_2B^{(2)}, \ldots, a_nB^{(m)}\end{pmatrix}
\end{multline*}
\end{proof}

\vspace{0.5cm}
\textit{Единичная матрица (порядка $n$)} --- квадратная матрица порядка $n$, элементы главной диагонали которой равны единице, а остальные равны нулю. Обозначается $E_n = \mathrm{diag}(1, 1, \ldots, 1)$.
\[E_n = 
\begin{pmatrix}
1 & 0 & \cdots & 0 \\
0 & 1 & \cdots & 0 \\         
\vdots & \vdots & \ddots & \vdots \\
0 & 0 & \cdots  & 1
\end{pmatrix}
\]
Основное свойство единичной матрицы --- при умножении матрицы $A$ на $E$ слева или справа $A$ не изменяется. Это доказывается элементарной проверкой.


% 11 - Вельдяйкин Николай
\subsection{След квадратной матрицы: определение, поведение при сложении, умножении на скаляр и транспонировании. След произведения двух матриц.}
\textit{Следом матрицы} $A$ называется сумма сумма всех диагональных элементов матрицы $A$. Обозначение: $\Tr A$ (от английского слова <<trace>> --- след). Альтернативное обозначение: $\mathrm{Sp}\ A$ (от немецкого слова <<spur>>): 
\[\Tr A \mathrel{:=} \sum_{i=1}^{n} a_{ii}\]
\textit{Свойства:}
\begin{enumerate}
\item $\Tr (A+B) = \Tr A + \Tr B$
\[\Tr (A + B) = \sum_{i=1}^{n} (a_{ii} + b_{ii}) = \sum_{i=1}^{n} a_{ii} + \sum_{i=1}^{n} b_{ii} = \Tr A + \Tr B\]

\item $\Tr \lambda A = \lambda \Tr A$
\[\Tr \lambda A = \sum_{i=1}^{n} \lambda a_{ii} = \lambda \sum_{i=1}^{n} a_{ii} = \lambda \Tr A\]

\item $\Tr A^T = \Tr A$\\
При транспонировании члены главной диагонали остаются на месте, т.к. $a_{ii}^T = a_{ii}$. Значит, и след не изменится.

\item $\forall A \in \Mat_{m \times n}, B \in \Mat_{n \times m}\; \Tr AB= \Tr BA$
\begin{proof}
Пусть $AB = X$, $BA = Y$. Тогда:
\[\Tr X = \sum_{k=1}^{m} x_{kk} = \sum_{k=1}^{m}\left(\sum_{l=1}^{n} a_{kl}b_{lk}\right) = \sum_{l=1}^{n}\left(\sum_{k=1}^{m} b_{lk} a_{kl}\right) = \sum_{l=1}^{n} y_{ll} = \Tr Y\]
\end{proof}
\end{enumerate}

% 12 - Гринберг Вадим
\subsection{Матричная форма записи системы линейных уравнений.\\ Совместные, несовместные, определённые и неопределённые системы линейных уравнений. Примеры.}

Пусть имеется система линейных уравнений из $m$ уравнений при  $n$ неизвестных:
\[\begin{cases}
a_{11}x_1 + a_{12}x_2 + \ldots + a_{1n}x_n = b_1\\
a_{21}x_1 + a_{22}x_2 + \ldots + a_{2n}x_n = b_2\\
\dotfill \\
a_{m1}x_1 + a_{m2}x_2 + \ldots + a_{mn}x_n = b_m
\end{cases}\]
Введём обозначения:
\[A = 
\begin{pmatrix}
a_{11} & a_{12} & \ldots & a_{1n} \\
a_{21} & a_{22} & \ldots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m1} & a_{m2} & \ldots & a_{mn} \\
\end{pmatrix} \text{--- \textit{матрица коэффициентов};}\]
\[\vec{x} = 
\begin{pmatrix}
x_1\\
x_2 \\
\ldots \\
x_n \\
\end{pmatrix}
\in \mathbb{R}^n \text{--- \textit{вектор неизвестных};\;} 
\vec{b} = 
\begin{pmatrix}
b_1\\
b_2 \\
\ldots \\
b_m \\
\end{pmatrix}
\in \mathbb{R}^m \text{--- \textit{вектор правых частей}.}\]

Тогда $A\vec{x} = \vec{b}$ называется \textit{матричной формой} записи СЛУ.

СЛУ называется \textit{совместной}, если у неё есть решения (хотя бы одно), и \textit{несовместной} в противном случае.

СЛУ называется \textit{определённой}, если у неё есть единственное решение, и \textit{неопределённой} в противном случае.

Основные вопросы теории СЛУ:
\begin{enumerate}
\item Когда СЛУ совместна? (см. \textit{ранг матрицы})
\item Когда СЛУ определена? (см. \textit{определитель матрицы})
\end{enumerate}

\textbf{Примеры:}

Система
\[\begin{cases}
3x - 2y = -6\\
5x + y = 3
\end{cases}\]
является совместной, так как имеет, по крайней мере, одно решение: $x = 0$, $y = 3$.

Система
\[\begin{cases}
5x + y = -6\\
5x + y = 3
\end{cases}\]
является несовместной, так как выражения, стоящие в левых частях уравнений системы равны, но правые части не равны друг другу. Ни для каких наборов $(x, y)$ это не выполняется.

Система
\[\begin{cases}
2x + 3y = 6\\
4x + 9y = 15
\end{cases}\]
является определённой, так как имеет единственное решение: $x = 1.5$, $y = 1$.

Система
\[\begin{cases}
x - y = 0\\
3x - 3y = 0
\end{cases}\]
является неопределённой, так как имеет бесконечно много решений $(x, y)$, где $x = y$.

% 13 - Иовлева Анастасия
\subsection{Определители второго и третьего порядков. Признак определённости системы двух линейных уравнений от двух неизвестных, формулы Крамера для такой системы.}
Введем два определения:

\textit{Определителем квадратной матрицы порядка два} $A = (a_{ij})$ называется число $\det A = a_{11}a_{22} - a_{21}a_{12}$.

\textit{Определителем квадратной матрицы порядка три} $A = (a_{ij})$ называется число $\det A =  a_{11} a_{22} a_{33} + a_{12} a_{23} a_{31} + a_{13} a_{21} a_{32} - a_{13} a_{22} a_{31} - a_{12} a_{21} a_{33} - a_{11} a_{23} a_{32}$.

Эту формулу можно запомнить, используя \textit{правило Саррюса}:

\begin{center}
\begin{tikzpicture}
    \matrix [%
      matrix of math nodes,
      column sep=1em,
      row sep=1em
    ] (sarrus) {%
      a_{11} & a_{12} & a_{13} & a_{11} & a_{12} \\
      a_{21} & a_{22} & a_{23} & a_{21} & a_{22} \\
      a_{31} & a_{32} & a_{33} & a_{31} & a_{32} \\
    }; 

    \path ($(sarrus-1-3.north east)+(0.5em,0)$) edge[dotted] ($(sarrus-3-3.south east)+(0.5em,0)$)
          (sarrus-1-1)                          edge         (sarrus-2-2)
          (sarrus-2-2)                          edge         (sarrus-3-3)
          (sarrus-1-2)                          edge         (sarrus-2-3)
          (sarrus-2-3)                          edge         (sarrus-3-4)
          (sarrus-1-3)                          edge         (sarrus-2-4)
          (sarrus-2-4)                          edge         (sarrus-3-5)
          (sarrus-3-1)                          edge[dashed] (sarrus-2-2)
          (sarrus-2-2)                          edge[dashed] (sarrus-1-3)
          (sarrus-3-2)                          edge[dashed] (sarrus-2-3)
          (sarrus-2-3)                          edge[dashed] (sarrus-1-4)
          (sarrus-3-3)                          edge[dashed] (sarrus-2-4)
          (sarrus-2-4)                          edge[dashed] (sarrus-1-5);

    \foreach \c in {1,2,3} {\node[anchor=south] at (sarrus-1-\c.north) {$+$};};
    \foreach \c in {1,2,3} {\node[anchor=north] at (sarrus-3-\c.south) {$-$};};
  \end{tikzpicture}
\end{center}

Теперь перейдем к СЛУ.

Имеем систему линейных уравнений.
$$
\begin{cases}
a_{11}x_1 + a_{12}x_2 = b_1 \\
a_{21}x_1 + a_{22}x_2 = b_2
\end{cases}
$$

Применим к ней метод исключения неизвестных. 

Домножим первую строку на $a_{22}$, вторую на $-a_{12}$ и сложим.
\begin{gather*}
(a_{11} a_{22} - a_{21}a_{12})x_1 + (a_{12}a_{22} - a_{22}a_{12})x_2 = b_1a_{22} - b_2a_{12} \\
(a_{11} a_{22} - a_{21}a_{12})x_1 = b_1a_{22} - b_2a_{12}
\end{gather*}
Теперь домножим первую строку изначальной системы на $-a_{21}$, а вторую на $a_{11}$. Сложим и аналогично получим:
$$
(a_{11}a_{22} - a_{21}a_{12})x_2 = b_2a_{11} - b_1a_{21}
$$

Заметим, что получили перед $x_1$ и $x_2$ одинаковый коэффициент. Обозначим его за $\Delta$. Правую часть первого равенства обозначим за $\Delta_1$, а второго — за $\Delta_2$. То есть получим следующее:
$$
\begin{cases}
\Delta x_1 = \Delta_1 \\
\Delta x_2 = \Delta_2
\end{cases}
$$

Соответственно, делаем вывод, что наша СЛУ имеет единственное решение (определенная СЛУ) тогда и только тогда, когда $\Delta \not=0$, причем это решение будет $x_1 = \Delta_1 / \Delta,\ x_2 = \Delta_2 / \Delta$. Если же $\Delta = 0$, то СЛУ неопределенная или несовместна.

Заметим, что $\Delta = \det A$, где $A$ — матрица коэффициентов нашей СЛУ. Заметим также, что $\Delta_1$ и $\Delta_2$ являются определителями следующих матриц:
\begin{center}
\begin{tabular}{cc}
$A_1 = \begin{pmatrix}
b_1 & a_{12} \\
b_2 & a_{22}
\end{pmatrix}$,
&
$A_2 = \begin{pmatrix}
a_{11} & b_1 \\
a_{21} & b_2
\end{pmatrix}$
\end{tabular}
\end{center}

\textit{Правило Крамера} для СЛУ с двумя уравнениями от двух неизвестных: если $\det A \not= 0$, то СЛУ является определенной и ее решение выражается формулой:
\begin{gather*}
x_1 = \frac{\det A_1}{\det A},\  x_2 = \frac{\det A_2}{\det A}
\end{gather*}

Если же мы будем рассматривать СЛУ с тремя уравнениями от трех переменных, то все тем же методом исключения неизвестных получим, что $x_1 = \frac{\det A_1} {\det A},\ x_2 = \frac{\det A_2}{\det A},\ x_3 = \frac{\det A_3}{\det A}$, где $A,\ A_1,\ A_2$ и $A_3$ — аналогичные матрицы.

% 14 - Попов Никита
\subsection{Перестановки и подстановки множества $\{1, 2, \ldots, n\}$. Инверсии в подстановке. Знак и чётность подстановки. Примеры.}
\textit{Перестановкой} из $n$ элементов множества $\{1, 2, \ldots , n\}$ называется всякий упорядоченный набор, в котором каждый элемент  встречается ровно один раз.
Число перестановок из $n$ элементов --- $P_n = n!$.

Назовём \textit{транспозицией} такое преобразование перестановки, при котором два её элемента меняются местами. Очевидно, все транспозиции обратимы.

\begin{proposal}
    Все $n!$ перестановок из $n$ элементов можно расположить в таком порядке, что каждая следующая получается из предыдущей одной транспозицией. При этом начинать можно с любой перестановки.
\end{proposal}
\begin{proof}
    Для $n = 2$ утверждение очевидно: $(1,2)\to(2,1)\to(1,2)$.

    Предположим, что утверждение верно для $n-1$ элемента. Докажем его для $n$:

    Пусть мы должны начать с перестановки $(i_1, i_2, \ldots, i_n)$. Рассмотрим все перестановки, начинающиеся с $i_1$. По предположению индукции мы можем их выстроить требуемым образом. Расставим их, после чего в последней из них переставим $i_1$ и, например, $i_2$. Будем повторять эту процедуру, пока не переберём все возможные первые элементы и получим требуемую расстановку.
\end{proof}

Из этого утверждения напрямую следует, что любую перестановку из $n$ симолов можно получить из любой другой некоторой комбинацией транспозиций.

Пусть \emph{подстановка} --- биективное отображение из множества $X = \{1, 2,\ldots, n\}$ в себя. Обозначение:
\[
    \sigma = 
    \begin{pmatrix}
        x_1&x_2&\ldots&x_n\\
        \sigma(x_1)&\sigma(x_2)&\ldots&\sigma(x_n)
    \end{pmatrix}
\]

Говорят, что $x_1$ переходит в $\sigma(x_1)$, $x_2$ переходит в $\sigma(x_2)$, и так далее.

Будем считать подстановки равными, если одни и те же элементы верхней строки переходят в одни и те же элементы нижней строки.

Мы будем рассматривать такие подстановки, где $x_i = i$ (из любой подстановки можно получить равную ей такого вида несколькими транспозициями столбцов).

Из этого очевидным образом следует, что подстановок на $n$ элементах тоже $n!$.

Назовём \emph{инверсией} такую пару индексов $i$ и $j$, что $i<j$, но $\sigma(i) > \sigma(j)$. Пусть всего инверсий в подстановке $s$, тогда назовём \emph{знаком} подстановки число $(-1)^s$. Подстановка называется \emph{чётной}, если её знак равен 1, и \emph{нечётной} в обратном случае.

Заметим, что транспозиция меняет чётность подстановки. В самом деле, это очевидно, если транспозиция меняет местами два соседних элемента. Иначе же её можно представить как $k$ транспозиций соседних элементов, чтобы поставить первый элемент после второго и $k-1$ --- чтобы поставить второй на место первого. Общее число транспозиций ($2k - 1$) нечётно, значит, знак меняется.

Следствием является то, что из подстановки $\left(\begin{smallmatrix}
    1&\ldots&n\\
    1&\ldots&n\\
\end{smallmatrix}\right)$ чётные подстановки получаются только чётным числом транспозиций и наоборот.


% 15 - Пузырёв Дмитрий
\subsection{Произведение подстановок: определение, ассоциативность,\\ некоммутативность.}
Как мы знаем, подстановка степени $n$ есть взаимно однозначное отображение множества $\{1, 2, \ldots, n\}$ на себя. Рассмотрим две подстановки. Результат последовательного выполения этих двух взаимно однозначных отображений на себя будет также являться взаимно-однозначным отображением. Тогда последовательное выполение двух перестановок степени $n$ приведёт к новой подстановке степени $n$. Эту новую подстановку будем называть $\textit{произведением}$ двух первых подстановок. Рассмотрим конкретный пример.
\[\sigma = \begin{pmatrix}1 & 2 & 3 & 4 \\ 3 & 1 & 4 & 2\end{pmatrix},\ \rho = \begin{pmatrix}1 & 2 & 3 & 4 \\ 1 & 3 & 4 & 2\end{pmatrix}\]
\[\sigma\rho = \begin{pmatrix}1 & 2 & 3 & 4 \\ 4 & 1 & 2 & 3\end{pmatrix}\]

При подстановке $\sigma$ $\textit{первый}$ элемент перешел в $\textit{третий}$. При подстановке $\rho$ $\textit{третий}$ элемент перешел в $\textit{четвертый}$. Тогда при последовательном выполнений $\textit{первый}$ перейдет в $\textit{четвертый}$ и так далее. Так получается произведение.

\begin{associativity_change}
Для произведения перестановок, взятых в определённом порядке, порядок выполнения умножения не играет роли. То есть $(\sigma_1 \sigma_2) \sigma_3 = \sigma_1 (\sigma_2 \sigma_3)$
\end{associativity_change}
\begin{proof}
Пусть даны перестановки $\sigma_1, \sigma_2, \sigma_3 \in S_n$. Рассмотрим какой-нибудь элемент $i_1, 1 \leqslant i_1 \leqslant n$. 

Пусть при подстановке $\sigma_1$ символ $i_1$ перейдёт в какой-то другой символ $i_2$, $i_2$, в свою очередь, при подстановке $\sigma_2$ перейдёт в $i_3$, а $i_3$ при подстановке $\sigma_3$ - в $i_4$. 

Получается, что по по определению умножения при подстановке $\sigma_1 \sigma_2$ $i_1$ перейдёт в $i_3$, а результат этой подстановки $i_3$ при подстановке $\sigma_3$ перейдет в $i_4$. По аналогичным соображениям при подстановке $\sigma_2 \sigma_3$ $i_2$ перейдёт в $i_4$, а $i_1$ при выполнении подстановки $\sigma_1$ перейдёт в $i_2$. При обеих операциях из $i_1$ в результате выполнения подстановок получилось $i_4$.
\end{proof}

Подстановки $\textit{некоммутативны}$, если их степени больше двух. Покажем это с помощью примера выше. Найдем $\rho\sigma$
\[\rho\sigma = \begin{pmatrix}1 & 2 & 3 & 4 \\ 3 & 4 & 2 & 1\end{pmatrix} \neq \begin{pmatrix}1 & 2 & 3 & 4 \\ 4 & 1 & 2 & 3\end{pmatrix} = \sigma\rho\]

Такие контрпримеры можно подобрать для подстановок любой степени, начиная с трёх.

В случае, если степень подстановок равна 2, коммутативность присутствует. Существуют всего две подстановки степени 2, одна из которых тождественна.
\[\sigma = \begin{pmatrix}1 & 2 \\ 1 & 2\end{pmatrix}, \rho = \begin{pmatrix}1 & 2 \\ 2 & 1\end{pmatrix}\]

Легко проверить, что любое произведение этих двух подстановок коммутирует. 

% 16 - Сухова Ольга
\subsection{Тождественная подстановка. Обратная подстановка. Знак обратной подстановки.}
\textit{Тождественная подстановка} — подстановка, которая переводит элементы сами в себя; $\id(x) = x,  \forall x$.  
\[\id = \begin{pmatrix}
	1 & 2 & \ldots & n \\
	1 & 2 & \ldots & n
\end{pmatrix}\]
Также отметим, что $\id\sigma = \sigma\id = \sigma$, где $\sigma$ --- некоторая подстановка.

\textit{Обратная подстановка} — такая подстановка $\sigma^{-1}$, что $\sigma \cdot \sigma^{-1} = \sigma^{-1} \cdot \sigma = \id$.
\[\sigma^{-1} = \begin{pmatrix}
	\sigma(1) & \sigma(2) & \ldots & \sigma(n) \\
	1 & 2 & \dots & n
\end{pmatrix}\]

\textbf{Лемма о знаке обратной подстановки:} $\sgn(\sigma) = \sgn(\sigma^{-1})$
\begin{proof}
Пусть пара $(i,j)$ образует инверсию в $\sigma$. Это значит, что $i < j$ и $\sigma(i) > \sigma(j)$. Но $i = \sigma^{-1}(\sigma(i))$ и $j = \sigma^{-1}(\sigma(j))$. Тогда $\sigma(i) > \sigma(j)$ и $\sigma^{-1}(\sigma(i)) < \sigma^{-1}(\sigma(j))$. Тогда $(\sigma(j), \sigma(i))$ образуют инверсию в $\sigma^{-1}$. Отсюда следует, что количество инверсий в $\sigma$ и $\sigma^{-1}$ совпадает $\implies \sgn(\sigma) = \sgn(\sigma^{-1})$
\end{proof}

% 17 - Хайдуров Руслан
\subsection{Транспозиции, элементарные транспозиции. Поведение знака подстановки при умножении слева на транспозицию. Количество чётных и нечётных подстановок.}
\textit{Транспозицией} называется такая подстановка, которая меняет два элемента местами. \textit{Элементарная транспозиция} — транспозиция, в которой меняются местами два соседних элемента.

\begin{lemma} 
    Пусть $\tau$ - транспозиция. Тогда $\sgn(\tau\sigma) = - \sgn(\sigma)$
\end{lemma}
\begin{proof}
Пусть транспозиция $\tau$ меняет местами элементы $i,j$, при этом $i<j$. Рассмотрим два случая:
\begin{enumerate}
\item $j = i + 1$. Произведение подстановок в таком случае равно 
\[\tau \sigma = \begin{pmatrix}
1 & 2 & \dots & i & j & \dots & n \\
\sigma(1) & \sigma(2) & \dots & \sigma(j) & \sigma(i) & \dots & \sigma(n) 
\end{pmatrix}\] 
Если пара $(p, q) \neq (i, j)$, то она  образует инверсию в $\sigma$ тогда и только тогда, когда она образует инверсию в $\tau \sigma$. $(i, j)$ образует инверсию в $\sigma \Leftrightarrow (i, j)$ не образуют инверсию в $\tau\sigma$.
Вывод: Число инверсий в $\sigma$ и $\tau \sigma$ отличаются на 1. А значит  $\sgn(\tau \sigma) = -\sgn(\sigma)$.

\item $j > i + 1$. Представим транспозицию $\tau_{ij}$ в виде композиции элементарных транспозиций: \[\tau_{ij} = \tau_{i(i+1)} \tau_{(i+1)(i+2)} \ldots \tau_{(j-2)(j-1)} \tau_{(j-1)j} \tau_{(j-2)(j-1)} \tau_{(j-3)(j-2)} \ldots \tau_{(i+1)i}\]
Однако очень легко посчитать количество транспозиций, в произведение которых мы их представили. Для перестановки чисел $i$ и $j$ нужно сначала перенести $i$ на позицию $j$, что займёт $j - i$ элементарных транспозиций. После этого число $j$ окажется на позиции $j - 1$. Тогда нужно $j - i - 1$ элементарная транспозиция для того, чтобы поставить число $j$ на позицию $i$. В итоге будет использовано $2(j - i) - 1$ элементарных транспозиций. Тогда знак подстановки умножился на $(-1)^{2(j-1) - 1} = -1$, т.е. подстановка поменяла знак.
\end{enumerate}
\end{proof}
\textit{Свойство.} При $n \geqslant 2$ число чётных подстановок в $S_n$ равно числу нечётных. Это можно легко заметить, если сопоставить каждой подстановке такую же, но умноженную на некоторую фиксированную транспозицию (например на $\tau_{12}$). Одна из полученных подстановок - чётная, другая - нечётная. Мы можем таким образом сделать биекцию между чётными и нечётными подстановками, а множества, между которыми можно сделать биекцию - равномощны.

% 18 - Хачиянц Алексей
\subsection{Общая формула для определителя квадратной матрицы произвольного порядка. Определитель транспонированной матрицы. Определитель матрицы, содержащей нулевую строку или нулевой столбец.}
Определитель квадратной матрицы порядка $n$ вводится следующим образом:
\[\det{A} = \sum_{\sigma \in S_n} \text{sgn}(\sigma)a_{1\sigma(1)}a_{2\sigma(2)}\ldots a_{n\sigma(n)} \quad (*)\]
\begin{T_det}
Определитель матрицы не изменяется от транспонирования (свойство Т): $\det A = \det A^T$ для любой $A \in \textsc{M}_{n}$ 
\end{T_det}
\begin{proof}
Распишем определитель $A^T$ по определению:
\[\det{A^T} = \sum_{\sigma \in S_n} \text{sgn}(\sigma)a_{\sigma(1)1}a_{\sigma(2)2}\ldots a_{\sigma(n)n}\]
Переставим элементы произведения так, чтобы их первые индексы шли в порядке возрастания. Это равносильно замене подстановки $\sigma$ на обратную к ней подстановку $\rho = \sigma^{-1}$. Так как количество инверсий в прямой и обратной подстановках совпадают, то их знаки совпадают и этот определитель равен
\[\sum_{\rho \in S_n} \text{sgn}(\rho)a_{1\rho(1)}a_{2\rho(2)}\ldots a_{n\rho(n)}\]
Но это равно $\det{A}$.
\end{proof}

Пусть в матрице есть нулевая строка. Из определения определителя следует, что каждый член суммы содержит по одному элементу с каждой строки. Но тогда все эти члены равны 0 и определитель равен 0. Для столбцов доказательство аналогично.

% 19 - Беляков Денис
\subsection{Поведение определителя при перестановке двух строк \\(столбцов). Определитель матрицы, содержащей две одинаковых строки (столбца).}

\begin{itemize}
\item 
\textit{При перестановке двух строк(столбцов) определитель меняет знак.} 
\begin{proof}
Принимая во внимание свойство $T$,\ достаточно доказать лишь для строк.

В самом деле, пусть в определителе переставляются лишь $i$-ая и $j$-ая строки,\ $i\ne j$, а все остальные строки остаются на месте. 
\[ (1)
\begin{vmatrix}
a_{11} & a_{12} & a_{13} & \cdots & a_{1n}\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
a_{i1} & a_{i2} & a_{i3} & \ldots & a_{in}\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
a_{j1} & a_{j2} & a_{j3} & \cdots & a_{jn}\\
\vdots & \vdots & \vdots &\ddots & \vdots\\
a_{n1} & a_{n2} & a_{n3} & \cdots & a_{nn}\\
\end{vmatrix} \to
\begin{vmatrix}
a_{11} & a_{12} & a_{13} & \cdots & a_{1n}\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
a_{j1} & a_{j2} & a_{j3} & \ldots & a_{jn}\\
\vdots & \vdots & \vdots & \ddots & \vdots\\
a_{i1} & a_{i2} & a_{i3} & \cdots & a_{in}\\
\vdots & \vdots & \vdots &\ddots & \vdots\\
a_{n1} & a_{n2} & a_{n3} & \cdots & a_{nn}\\
\end{vmatrix}
(2)
\]
Если $a_{1,\alpha_1} a_{2,\alpha_2}\ldots a_{n,\alpha_n}$ есть член определителя (1), то все его множители в определителе (2) остаются, очевидно, в разных строках и в разных столбцах. Таким образом, определители (1) и (2) состоят из одних и тех же членов. Этому члену в определителе (1) соответствует подстановка
\[
\begin{pmatrix}
1 & 2 & \ldots & i & \ldots & j & \ldots & n\\
\alpha_1 & \alpha_2 & \ldots & \alpha_i & \ldots & \alpha_j & \ldots  & \alpha_n
\end{pmatrix} \; (3)
\]
а в определителе (2) -- подстановка
\[
\begin{pmatrix}
1 & 2 & \ldots & i & \ldots & j & \ldots & n\\
\alpha_1 & \alpha_2 & \ldots & \alpha_j & \ldots & \alpha_i & \ldots  & \alpha_n
\end{pmatrix} \; (4)
\]
так как, например, элемент $a_{i\alpha_i}$ стоит теперь в $j$-ой строке, но остается в старом $\alpha_i$-ом столбце. Подстановка (4) получается, однако, из подстановки (3) путем одной транспозиции в нижней строчке, т.е. имеет противоположную четность. Отсюда следует, что все члены определителя (1) входят в определитель (2) с обратными знаками, т.е. определители (1) и (2) отличаются лишь знаком.
\end{proof}
\item \textit{Определитель, содержащий две одинаковые строки (столбца), равен нулю.}
\begin{proof}
Принимая по внимания свойство $T$,\ достаточно доказать лишь для строк.

В самом деле, пусть определитель равен $d$ и пусть соответственные элементы его $i$-ой и $j$-ой строк $(i \neq j)$ равны между собой. После перестановки этих двух строк определитель станет равен (ввиду выше доказанного свойства) числу $-d$. Так как, однако, переставляются одинаковые строки, то определитель не меняется, т.е. $d = -d$, откуда $d = 0$ 
\end{proof}
\end{itemize}

% 20 - Вельдяйкин Николай
\subsection{Поведение определителя при умножении строки (столбца) на скаляр, разложении строки (столбца) в сумму двух, прибавлении к строке (столбцу) другой, умноженной на скаляр.}

\textbf{Умножение на скаляр:} \textit{Если в $A$ \textit{все элементы некоторой строки умножить на одно и то же число} $\lambda$, то определитель увеличится в $\lambda$ раз: \[B_{(i)} = \lambda A_{(i)}, B_{(j)} = A_{(j)}, i \neq j \implies \det{B} = \lambda\det{A}\] (Аналогичное свойство для столбцов из свойства $T$.)}
\begin{proof}
В формуле определителя для $B$ в каждом слагаемом присутствует $\lambda a_{i \sigma(i)}$ (только один) $\Rightarrow$ каждое слагаемое для $\det(B)$ получается умножением на $\lambda$ соответствующего слагаемого для $\det(A) \Rightarrow \det(B) = \lambda \det(A)$.
\end{proof}

\textbf{Разложение строки в сумму двух:} \textit{Пусть какая-то строка $A_{(i)}$ раскладывается в сумму двух строк $A_{(i)}'$ и $A_{(i)}''$, а все остальные остаются неизменными. Тогда $\det{A} = \det{A'} + \det{A''}$. (Аналогичное свойство для столбцов из свойства $T$.)}
\begin{proof}
\begin{multline*}
\det{A} = \sum_{\sigma \in S_n} \sgn(\sigma)a_{1\sigma(1)}\dots a_{i\sigma(i)}\dots a_{n\sigma(n)} = \sum_{\sigma \in S_n} \sgn(\sigma)a_{1\sigma(1)}\dots (a_{i \sigma(i)}'+ a_{i \sigma(i)}'')\dots a_{n\sigma(n)} = \\ = \sum_{\sigma \in S_n}\sgn(\sigma)a_{1\sigma(1)}\dots a_{i\sigma(i)}'\dots a_{n\sigma(n)} + \sum_{\sigma \in S_n}\sgn(\sigma)a_{1\sigma(1)}\dots a_{i\sigma(i)}''\dots a_{n\sigma(n)} = \det(A')+ \det(A'')
\end{multline*}
\end{proof}

\textbf{Прибавление строки:} \textit{Если к какой-либо строке прибавить другую строку, умноженную на скаляр, то определитель не изменится.}
\begin{proof}
$B_{(i)} = A_{(i)}, B_{(k)} = A_{(k)} + \lambda A_{(j)}, i \neq k$
\begin{gather*}
\det{B} = \det
\begin{pmatrix}
    B_{(1)}\\
    \vdots\\
    B_{(i)}\\
    \vdots\\
    B_{(n)}
\end{pmatrix}
= \det
\begin{pmatrix}
    A_{(1)}\\
    \vdots\\
    A_{(i)} + \lambda A_{(j)}\\
    \vdots\\
    A_{(n)}
\end{pmatrix}
= \det
\begin{pmatrix}
    A_{(1)}\\
    \vdots\\
    A_{(i)}\\
    \vdots\\
    A_{(n)}
\end{pmatrix}
+ \lambda \det
\begin{pmatrix}
    A_{(1)}\\
    \vdots\\
    A_{(j)}\\
    \vdots\\
    A_{(n)}
\end{pmatrix}
= \\ =
\left \lbrace 
\begin{aligned}
&\text{во второй матрице}\\
&\text{оказалось две} \\
&\text{одинаковые строки} 
\end{aligned}
\right \rbrace \det{A} + 0 = \det{A}
\end{gather*}
Для столбцов свойство будет аналогичным в связи со свойством $T$.
\end{proof}

% 21 - Гринберг Вадим
\subsection{Верхнетреугольные и нижнетреугольные матрицы. Определитель верхнетреугольной и нижнетреугольной матрицы. Определитель диагональной матрицы. Определитель единичной матрицы.}

Матрица $A \in  M_n$ – $\textit{верхнетреугольная}$, если
$a_{ij} = 0$  при  $i > j$  (т.е. ниже диагонали).

Матрица $A \in  M_n$ – $\textit{нижнетреугольная}$, если
$a_{ij} = 0$  при  $i < j$  (т.е. выше диагонали).

\begin{que21prop}
если  $A \in  M_n$ – верхнетреугольная (нижнетреугольная) матрица, то $\det A = a_{11} \cdot a_{22} \cdot \ldots \cdot a_{nn}$ --- произведение всех элементов главной диагонали.
\end{que21prop}

\begin{proof}
По свойству $T$ достаточно доказать для верхнетреугольной матрицы.

Пусть $A$ – верхнетреугольная матрица. Возьмём подстановку $\sigma \in S_n$ и соответсвующее ему слагаемое определеителя $P = \sgn(\sigma) \cdot a_{1\sigma_1} \cdot a_{2\sigma_2} \cdot \ldots \cdot a_{n\sigma_n}.$

Если $P \neq 0$, то, так как ниже диагонали идут нули, необходимо, чтобы $\sigma_1 \geq 1, \sigma_2 \geq 2, \ldots , \sigma_n \geq n$. Из этих неравенст и того, что подстановка обладает свойством инъективности, следует, что $\sigma_1 = 1, \sigma_2 = 2 , \ldots , \sigma_n = n$. Иными словами,
$\sigma  =\id$. Так как $\sgn (\id) = 1$, получаем, что $P = a_{11} a_{22} \ldots a_{nn}$, и больше других ненулевых слагаемых определеителя нет.

Итого, $\det A = a_{11} a_{22} \ldots a_{nn}$.
\end{proof}

\textbf{Следствия:}
\begin{enumerate}
\item Определитель диагональной матрицы $\det A = \det (\diag (a_1, a_2, \ldots , a_n)) = a_1 \cdot a_2 \cdot \ldots \cdot a_n$, т.к. диагональная матрица одновременно и верхнетреугольная, и нижнетреугольная. 
\item Определитель единичной матрицы  $\det E = 1$, т.к. она --- диагональная с единицами по диагонали.
\end{enumerate}

\textbf{Замечание:} любой определитель можно вычислить, приведя матрицу к верхнетреугольному виду (см. элементарные преобразования).

% 22 - Иовлева Анастасия
\subsection{Разложение подстановки в произведение транспозиций и элементарных транспозиций. Знак произведения подстановок.}
\begin{que22lemma1}
Любая подстановка представима в виде произведения транспозиций.
\end{que22lemma1}

\begin{proof}
Докажем с помощью индукции по $n$.

$n=2$. Тогда либо $\sigma = \tau_{12}$, либо $\sigma = \tau_{12}\tau_{21} = \id$.

$n >  2$. Пусть $s = \sigma^{-1}(n)$, то есть $\sigma(s) = n$. Тогда рассмотрим два случая: когда $s = n$ и когда $s <  n$.

Если $s = n$, то ее разложение есть суть разложения подстановки $\sigma' \in S_{n-1}$, так как $n$-ый элемент ничего не меняет. А для $\sigma'$, по индукционному предположению, такое разложение существует. Соответственно, такое же разложение имеет место в $\sigma$.

Если $s < n$, рассмотрим подстановку $\tau_{sn}\sigma$. Тогда:
$$
(\tau_{sn}\sigma)(n) = \sigma(\tau_{sn}(n)) = \sigma(s) = n
$$
Итого, эта подстановка относится к предыдущему случаю, когда последний элемент ничего не изменяет, и для него по индукционному предположению есть некое разложение: $\tau_{sn}\sigma = \tau_1\tau_2\dots\tau_k
$. Домножим слева на $\tau_{ns}$:
\begin{gather*}
\tau_{ns} \cdot \tau_{sn}\sigma = \tau_{ns} \cdot \tau_1\tau_2\dots\tau_k \\
\id \cdot \sigma = \tau_{ns} \cdot \tau_1\tau_2\dots\tau_k \\
\sigma = \tau_{ns} \cdot \tau_1\tau_2\dots\tau_k
\end{gather*}
Итого, получили искомое разложение. Следовательно, лемму можно считать доказаной.
\end{proof}

\begin{que22lemma2}
Любая подстановка представима в виде произведения элементарных транспозиций.
\end{que22lemma2}
\begin{proof}
Непосредственно следует из леммы 1 и того, что любая транспозиция представима в виде произведения элементарных транспозиций. На всякий случай, рассмотрим второе чуть подробней:
$$
\tau_{ij} = \tau_{i, i+1} \cdot  \tau_{i+1, i+2} \dots \tau_{j-1, j} \cdot \tau_{j-1, j-2} \dots \tau_{i+1, i}
$$
То есть сначала мы двигаем $i$-ый элемент до $j$-ой позиции, после чего то, что раньше было на $j$-ом месте, стоит на $j-1$-ом, и мы двигаем его обратно на $i$-ую позицию. 
\end{proof}

\begin{que22theorem}
Знак произведения подстановок есть произведения знаков подстановок: $\sgn (\sigma\rho) = \sgn \sigma \sgn \rho$.
\end{que22theorem}

\begin{proof}
По лемме 1 подстановка $\sigma$ представима в виде произведение транспозиций: $\sigma = \tau_1\tau_2\dots\tau_k$. Каждая транспозиция есть суть инверсия, и потому меняет знак подстановки. Следовательно:
$$
\sgn(\sigma) = \sgn(\tau_1\tau_2\dots\tau_k) = (-1)\sgn(\tau_2\dots\tau_k) = (-1)^2\sgn(\tau_3\dots\tau_k) = \dots = (-1)^k
$$

Аналогично, для произведения подстановок получим:
$$
\sgn(\sigma\rho) = \sgn(\tau_1\tau_2\dots\tau_k\rho) = (-1)\sgn(\tau_2\dots\tau_k\rho) = \dots = (-1)^k \sgn(\rho) = \sgn(\sigma)\sgn(\rho)
$$
\end{proof}

% 23 - Попов Никита
\subsection{Полилинейные и кососимметрические функции от нескольких аргументов. Примеры. Значение кососимметрической\\ функции от $n$ столбцов высоты $n$ на наборе из $n$ единичных столбцов.}
Назовём функцию от нескольких аргументов \emph{полилинейной}, если она линейна по всем аргументам. Иначе, функция $f(x_1, \ldots, x_n)$ полилинейна тогда и только тогда, если для всех $i \in \left\{ 1, \ldots, n \right\}$ выполняется
\[
     f(x_1,\ldots,\ \alpha x_i + \beta x'_i, \ldots , x_n) = \alpha f(x_1,\ldots,\ x_i, \ldots , x_n) + \beta f(x_1,\ldots,\ x'_i, \ldots , x_n)
\]

Назовём функцию от нескольких аргументов \emph{кососимметрической}, если для всех \\$i, j \in \left\{ 1, \ldots, n \right\}$, $i \neq j$ выполняется
\[
     f(x_1,\ldots,\ x_i ,\ldots,\ x_j, \ldots , x_n) = -f(x_1,\ldots,\ x_j,\ldots,\ x_i \ldots , x_n)
\]

\textbf{Примеры:}
\begin{itemize}
\item Определитель матрицы является полилинейной кососимметрической функцией от строк матрицы;
\item $f(x, y) = x-y$ --- кососимметрическая, но не полилинейная;
\item $f(x_1, x_2, x_3, x_4) = x_1\cdot x_2\cdot x_3\cdot x_4$ --- полилинейная, но не кососимметрическая.
\end{itemize}

Рассмотрим функцию $f(e_1, \ldots, e_n)$, где $e_i \in \mathbb{R}^n$ --- какой-то единичный столбец. Тогда:
\begin{itemize}
\item Если среди $e_1, \ldots, e_n$ есть хотя бы 2 одинаковых, то $f(e_1, \ldots, e_n) = 0$ в силу кососимметричности, т.к., переставив эти два одинаковых столбца местами, мы изменим знак, но при этом значение измениться не должно. Значит, значение функции --- $0$.
\item Если все $e_1, \ldots, e_n$ различны, то при перестановке 2-х столбцов меняться будет только знак, значение по модулю же останется прежним. Следовательно: $f(e_1, \ldots, e_n) = \pm f(E)$, где $E$ --- единичная матрица.
\end{itemize}

% 24 - Иовлева Анастасия
\subsection{Теорема о полилинейной кососимметрической функции строк (столбцов) квадратной матрицы. Аксиоматическое определение определителя.}
Пусть строки $e_i,\ i \in \{1, \ldots, n\}$ получены из нулевых строк подстановкой 1 на $i$-ую позицию.
\begin{gather*}
e_1 = (1, 0, \ldots, 0, 0) \\
e_2 = (0, 1, \ldots, 0, 0) \\
\ldots\ldots \\
e_n = (0, 0, \ldots, 0, 1)
\end{gather*}

\begin{que24lemma}
Пусть $f$ — полилинейная кососимметрическая функция от $n$ строк длины $n$. Тогда $\forall \sigma \in S_n$ верно, что
$$
f(e_{\sigma(1)}, e_{\sigma(2)}, \ldots, e_{\sigma(n)}) = \sgn(\sigma)f(e_1, e_2, \ldots, e_n)
$$
\end{que24lemma}

\begin{proof}
Разложим $\sigma$ в произведение транспозиций:
$$
\sigma = \tau_{p_1, q_1} \cdot \tau_{p_2, q_2} \cdot \ldots \cdot \tau_{p_k, q_k}
$$
Теперь в выражении $f(e_{\sigma(1)}, e_{\sigma(2)}, \ldots, e_{\sigma(n)})$ выполним эти перестановки (с конца):
\begin{gather*}
e_{p_k} \leftrightarrow e_{q_k} \\
e_{p_{k-1}} \leftrightarrow e_{q_{k-1}} \\
\ldots\ldots \\
e_{p_1} \leftrightarrow e_{q_1}
\end{gather*}
В силу кососимметричности, при выполнении каждой такой перестановки функция будет менять знак. Поэтому в результате получим $(-1)^k f(e_1, e_2, \ldots, e_n)$. Осталось только заметить, что $(-1)^k = \sgn(\sigma)$.
\end{proof}

\begin{que24theorem}
Пусть $f$ — полилинейная кососимметрическая функция от строк матрицы $A \in Mat_n$. Тогда
$$
f(A) = f(E)\det A
$$
\end{que24theorem}

\begin{proof}
Рассмотрим строки матрицы $A$: $A_{(1)}, A_{(2)}, \ldots, A_{(n)}$. Заметим, что каждую такую строку можно выразить через введенные нами строки $e$:
\begin{gather*}
A_{1} = (a_{11}, a_{12}, \ldots, a_{1n}) = a_{11}\cdot e_1 + (0, a_{12}, \ldots, a_{1n}) = \ldots = \sum_{i_1 = 1}^{n}a_{1i_1}e_{i_1} \\
A_{(2)} = \sum_{i_2 = 1}^{n} a_{2i_2} e_{i_2} \\
\ldots\ldots\\
A_{(n)} = \sum_{i_n = 1}^{n} a_{ni_n} e_{i_n}
\end{gather*}

Тогда перезапишем с помощью этого $f(A)$:
\begin{gather*}
f(A) = f(A_{(1)}, A_{(2)}, \ldots, A_{(n)}) = \\
= f(\sum_{i_1 = 1}^{n}a_{1i_1}e_{i_1},  A_{(2)}, \ldots, A_{(n)})
\end{gather*}

Наша функция полилинейна, так что воспользуемся линейностью по первому аргументу.
$$
f(A) = \sum_{i_1 = 1}^{n}a_{1i_1} f(e_{i_1}, A_{(2)}, \ldots, A_{(n)})
$$

Аналогичные действия мы можем проделать со всеми строками, и в итоге получим:

$$
f(A) = \sum_{i_1 = 1}^{n} \sum_{i_2 = 1}^{n} \ldots \sum_{i_n = 1}^{n}a_{1i_1}a_{2i_2}\ldots a_{ni_n} f(e_{i_1}, e_{i_2}, \ldots, e_{i_n})
$$

Заметим, что если среди чисел $i_1, i_2, \ldots i_n$ есть одинаковые, то $f(e_{i_1}, e_{i_2}, \ldots, e_{i_n}) = 0$ из кососимметричности (так как знак должен поменяться при перестановке любых двух аргументов, в том числе если мы переставим равные). А если все числа различны, то тогда существует такая подстановка $\sigma \in S_n$, что $i_1 = \sigma(1), i_2 = \sigma(2), \ldots, i_n = \sigma(n)$.
$$
f(A) = \sum_{\sigma \in S_n}a_{1\sigma(1)}a_{2\sigma(2)}\ldots a_{n\sigma(n)} f(e_{\sigma(1)}, e_{\sigma(2)}, \ldots, e_{\sigma(n)})
$$
Применим доказанную ранее лемму и заметим, что получили определитель:
\begin{gather*}
f(A) = \sum_{\sigma \in S_n}a_{1\sigma(1)}a_{2\sigma(2)}\ldots a_{n\sigma(n)} \sgn(\sigma) f(e_1, e_2, \ldots, e_n) = \\
= f(e_1, e_2, \ldots, e_n) \cdot \sum_{\sigma \in S_n} \sgn(\sigma)a_{1\sigma(1)}a_{2\sigma(2)}\ldots a_{n\sigma(n)} = \\
= f(E) \det A
\end{gather*}
\end{proof}

\begin{que24cons}
Единственная полилинейная кососимметрическая функция от строк матрицы $A$, равная 1 на $E$, есть $\det A$.

Аналогично для столбцов (по свойству $T$).
\end{que24cons}

% 25 - Сухова Ольга
\subsection{Определитель произведения матриц.}
Пусть $A, B$ — квадратные матрицы рамера $n$. Тогда $\det{AB} = \det{A}\cdot\det{B}$

\begin{proof}
\begin{gather*}
(AB)_{(i)}=A_{(i)}B \\
\det(AB)=\det( (AB)_{(1)}, \ldots, (AB)_{(n)} ) = \det (A_{(1)}B, \ldots, A_{(n)}B )
\end{gather*}

Рассмотрим определитель как функцию от строк матрицы $A$, зафиксировав $B$. По аксиоматическому определению эта функция является полилинейной кососимметрической функцией. Тогда по теореме о полилинейной кососимметрической функции строк из предыдущего билета: 
$$\det(AB) = \det(A) \cdot \det (EB) = \det(A) \cdot \det(B).$$
\end{proof}

% 26 - Хайдуров Руслан
\subsection{Определитель с углом нулей.}
\textit{Матрицей с углом нулей} называется квадратная блочная матрица вида
\[
C =
\begin{pmatrix}
A & P\\
0 & B
\end{pmatrix},
\quad
D =
\begin{pmatrix}
A & 0\\
P & B
\end{pmatrix}
\]
\begin{zero_angle}
Пусть есть матрицы $C$ и $D$ с углом нулей, где на месте $P$ могут стоять произвольные числа, а на месте 0 --- нулевая матрица. При этом матрицы $A \in M_k\left(\mathbb R\right)$ и $B \in M_n\left(\mathbb R\right)$ — квадратные. Тогда определитель $\det{C} = \det{D} = \det{A}\det{B}$.
\end{zero_angle}
\begin{proof}
Докажем для матрицы $C$, так как для $D$ аналогично (по свойству $T$).

Рассмотрим $f = \det{C}$ --- функцию от столбцов $A$, зафиксировав $P$ и $B$. Тогда $f$ --- полилинейная кососимметрическая функция, следовательно,

$$\det{C} = \det{A} \cdot 
\begin{vmatrix}
E_k & P\\
0 & B
\end{vmatrix}.$$

Теперь рассмотрим 
$\begin{vmatrix}
E_k & P\\
0 & B
\end{vmatrix}$ как функцию $g$ от строк матрицы $B$, зафиксировав $P$. Тогда $g$ --- полилинейная кососимметрическая функция, следовательно,

$$\det{C} = \det{A} \cdot \det{B} \cdot
\begin{vmatrix}
E_k & P\\
0 & E_n
\end{vmatrix}.$$

Заметим, что матрица
$\begin{pmatrix}
E_k & P\\
0 & E_n
\end{pmatrix}$ --- верхнетреугольная с единицами на диагонали, значит её определитель равен 1. Тогда $\det{C} = \det{A}\det{B}$.
\end{proof}

% 27 - Хачиянц Алексей
\subsection{Дополнительный минор и алгебраическое дополнение к элементу квадратной матрицы. Разложение определителя по\\ строке (столбцу).}
\textit{Дополнительным минором} к элементу $a_{ij}$ матрицы $A \in \mathrm{M}_n$ называют определитель матрицы, полученной из $A$ удалением $i$-ой строки и $j$-го столбца:
\[\overline{M}_{ij} = \begin{vmatrix}
a_{11} & a_{12} & \ldots & a_{1(j-1)} & a_{1(j+1)} & \ldots & a_{1n} \\
a_{21} & a_{22} & \ldots & a_{2(j-1)} & a_{2(j+1)} & \ldots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots     & \vdots     & \ddots & \vdots \\
a_{(i-1)1} & a_{(i-1)2} & \ldots & a_{(i-1)(j-1)} & a_{(i-1)(j+1)} & \ldots & a_{(i-1)n} \\
a_{(i+1)1} & a_{(i+1)2} & \ldots & a_{(i+1)(j-1)} & a_{(i+1)(j+1)} & \ldots & a_{(i+1)n} \\
\vdots & \vdots & \ddots & \vdots     & \vdots     & \ddots & \vdots \\
a_{n1} & a_{n2} & \ldots & a_{n(j-1)} & a_{n(j+1)} & \ldots & a_{nn} \\
\end{vmatrix}\]
\textit{Алгебраическим дополнением} элемента $a_{ij}$ матрицы $A \in \mathrm{M}_n$ называют число $A_{ij} = (-1)^{i+j}\overline{M}_{ij}$

\begin{laplace_theorem}
Пусть выбрана $i$-я строка матрицы $A \in \mathrm{M}_n$. Тогда определитель матрицы $A$ равен сумме всех элементов строки, умноженных на их алгебраические дополнения:
\[\det{A} = \sum_{k = 1}^{n} a_{ik}A_{ik}\]
Для столбца формулировка аналогична.
\end{laplace_theorem}
\begin{proof}
Так как определитель не изменяется от транспонирования, то достаточно рассмотреть разложение по строке.
Докажем следующее утверждение:
\[\begin{vmatrix}
a_{11} & 0 & 0 & \ldots & 0 \\
a_{21} & a_{22} & a_{23} & \ldots & a_{2n} \\
a_{31} & a_{32} & a_{33} & \ldots & a_{3n} \\
\vdots & \vdots & \vdots & \ddots & \vdots \\
a_{n1} & a_{n2} & a_{n3} & \ldots & a_{nn} \\
\end{vmatrix} = a_{11}
\begin{vmatrix}
a_{22} & a_{23} & \ldots & a_{2n} \\
a_{32} & a_{33} & \ldots & a_{3n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n2} & a_{n3} & \ldots & a_{nn} \\
\end{vmatrix} = a_{11}\overline{M}_{11}\]
Для этого рассмотрим определитель по определению. Заметим, что $\sigma(1) = 1$ (иначе член обнуляется). Тогда $\sigma = \rho \in S_{n-1}$ и определитель равен $a_{11}\sum\limits_{\rho \in S_{n-1}} \sgn(\rho)a_{2\rho(2)}\ldots a_{n\rho(n)}$. А это в свою очередь равно
\[a_{11}\begin{vmatrix}
a_{22} & a_{23} & \ldots & a_{2n} \\
a_{32} & a_{33} & \ldots & a_{3n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{n2} & a_{n3} & \ldots & a_{nn} \\
\end{vmatrix}\]
Теперь вернёмся к основному рассуждению. Разложим $i$-ю строку матрицы в сумму строк вида $(0,\ldots, a_{ij}, \ldots, 0)$. Тогда определитель разобъётся в сумму определителей, где вместо $i$-й строки будет стоять строка такого вида, а все остальные останутся на месте. Переставим элемент с позиции $(i, j)$ на позицию $(1, 1)$ с помощью перестановок соседних строк, а затем столбцов. На это понадобится $i+j-2$ перестановки. Тогда $i$-я строка станет первой, а $j$-й столбец --- тоже первым. Тогда согласно ранее доказанному утверждению, этот определитель равен $(-1)^{i+j}a_{ij}\overline{M}_{ij} = a_{ij}A_{ij}$. Тогда \[\det{A} = \sum_{k = 1}^{n} a_{ik}A_{ik}\]
\end{proof}

% 28 - Беляков Денис
\subsection{Лемма о фальшивом разложении определителя.}

\begin{fake-determinant}
Сумма произведений всех элементов некоторой фиксированной строки (столбца) матрицы $A$ на алгебраические дополнения соответствующих элементов любой другой фиксированной строки (столбца) равна нулю.
\vspace{0.5cm}

При фиксированных $i,\ k \in \{1, \ldots, n\},\ i \ne k$
$$ \sum_{j=1}^n a_{ij} A_{kj} = 0 $$

При фиксированных $j,\ m \in \{1, \ldots, n\},\ j \ne k$
$$ \sum_{i=1}^n a_{ij} A_{im} = 0 $$
\end{fake-determinant}

\begin{proof}
Свойство $T$ --- достаточно доказать для строк.

Рассмотрим матрицу $B$, полученную из $A$ заменой $i$-ой строки на $k$-ую.
Тогда  
\[
\sum_{j=1}^n b_{ij} B_{kj} = 
\sum_{j=1}^n a_{ij} A_{kj}
\]
есть разложение определителя матрицы $B$ по $k$-ой строке.
Также ввиду свойства определителя о наличии двух одинаковых строк (столбцов), $\det{B} = 0$

Заметим, что алгебраические дополнения элементов $i$-ой строки матрицы $B$ совпадают с алгебраическими дополнениями соответствующих элементов $i$-ой строки матрицы $A$. 
Но элементами $i$-ой строки матрицы $B$ являются соответствующие элементы $k$-ой строки матрицы $A$. 
Таким образом, сумма произведений всех элементов $i$-ой строки матрицы $B$ на их алгебраические дополнения с одной стороны равна нулю, 
а с другой стороны равна сумме произведений всех элементов $k$-ой строки матрицы $A$ на алгебраические дополнения соответствующих элементов $i$-ой строки матрицы $A$.
\end{proof}

% 29 - Вельдяйкин Николай
\subsection{Обратная матрица, её единственность. Определитель обратной матрицы.}
\begin{definition}
Матрица $B \in M_n$ называется \textit{обратной матрицей} к $A$, если $AB = BA = E$. Обозначение: $A^{-1}$.
\end{definition}
\begin{theorem}
Если обратная матрица существет, то она \textit{единственная}:
\end{theorem}

\begin{proof}
Пусть $B$ и $B'$ - две обратные к $A$ матрицы.
\[B = EB = (B'A)B = B'(AB) = B'E = B'\]
\end{proof}

\begin{definition}
Матрица $A$ называется невырожденной, если для нее существует обратная матрица.
\end{definition}

\begin{theorem}
Если матрица $A$ невырожденная, то $\det(A) \neq 0$ и $\det(A^{-1})= \frac{1}{\det(A)}$:
\end{theorem}

\begin{proof} Воспользуемся тем, что произведение определителей есть опредеделитель произвденения (\textit{см. билет 25}).
\[\det(A) \cdot \det(A^{-1}) = \det(A\cdot A^{-1}) = \det(E) = 1 \Rightarrow \det(A) \neq 0, \det(A^{-1})= \frac{1}{\det(A)}\]
\end{proof}

% 30 - Гринберг Вадим
\subsection{Матрица, присоединённая к данной. Критерий существования обратной матрицы. Явная формула для обратной матрицы. Матрица, обратная к произведению двух матриц.}
\textbf{Матрица, присоединённая к $A$} — $\hat{A} = (A_{ij})^T$ — матрица из алгебраических дополнений: 
\[\hat A = \begin{pmatrix}
A_{11} & A_{21} & A_{31} & \ldots & A_{n1} \\
A_{12} & A_{22} & A_{32} & \ldots & A_{n2} \\
A_{13} & \ldots & \ldots & \ldots & \vdots \\
\vdots & \ldots & \ldots & \ddots & \vdots \\
A_{1n} & \ldots & \ldots & \ldots & A_{nn} \\
\end{pmatrix}.\]

\begin{que30theorem}
Матрица А --- \textit{невырожденная} (имеет обратную) $\iff$ $\det A \neq 0$, при этом $A^{-1} = \frac{1}{\det A} \cdot \hat{A}$
\end{que30theorem}

\begin{proof}
$\Rightarrow$ --- лемма об определителе обратной матрицы (смотрите выше).

$\Leftarrow$ : Пусть $\det A \neq 0 \Rightarrow$ достаточно доказать, что $\hat{A} \cdot A = \det A \cdot E$.

Пусть $\hat{A} = B \Rightarrow b_{ij} = A_{ji}$ по определению $\Rightarrow$.

\begin{enumerate}
  \item Для $X = A \cdot \hat{A}$ выполнено:
  $$
  x_{ij} = \sum_{k = 1}^{n} a_{ik} \cdot b_{kj} = \sum_{k = 1}^{n} a_{ik} \cdot A_{jk} = 
  \begin{cases}
  \det A, & \text{если $i = j$ (разложение по $i$-ой строке)}\\
  0, & \text{если $i \neq j$ (фальшивое разложение)}\\
  \end{cases}
  $$
  \item Для $Y = \hat{A} \cdot A$ выполнено:
  $$y_{ij} = \displaystyle\sum_{m = 1}^{n} b_{im} \cdot a_{mj} = \displaystyle\sum_{m = 1}^{n} A_{mi} \cdot a_{mj} = 
  \begin{cases}
  \det A, & \text{если $i = j$ (разложение по i-ой строке)}\\
  0, & \text{если $i \neq j$ (фальшивое разложение)}\\
  \end{cases}
  $$
\end{enumerate}

Таким образом, $\hat{A} \cdot A = \det A \cdot E$, откуда следует, что $A^{-1} = \frac{1}{\det A} \cdot \hat{A}$.
\end{proof}

\begin{que30cons1}
Если $A, B \in M_n$ и $AB = E$, то $BA = E$.
\end{que30cons1}

\begin{proof}
$
AB = E \Rightarrow \det A \cdot \det B = 1 \Rightarrow \det A \neq 0 \Rightarrow A \text{ — невырожденная} \Rightarrow BA = E \cdot BA = (A^{-1} \cdot A)BA = A^{-1}(AB)A = A^{-1} \cdot E \cdot A = E.
$
\end{proof}

\begin{que30cons2}
Если $A, B$ --- невырожденные, то $AB$ --- тоже невырожденная, причём $(AB)^{-1} = B^{-1} \cdot A^{-1}$.
\end{que30cons2}

\begin{proof}
$
A, B \text{--- невырожденные} \Rightarrow \det A \neq 0, \det B \neq 0 \Rightarrow \det AB = \det A \cdot \det B \neq 0 \Rightarrow AB \text{--- невырожденная} \Rightarrow (B^{-1} \cdot A^{-1}) \cdot AB = B^{-1} \cdot A^{-1} \cdot A \cdot B = B^{-1} \cdot E \cdot B = B^{-1} \cdot B = E \Rightarrow (B^{-1} \cdot A^{-1}) = (AB)^{-1}.
$
\end{proof}

\textbf{Утверждение:} если $A$ --- невырожденная, то $A^{-1}$ --- тоже невырожденная, а значит, $(A^{-1})^{-1} = A$.


% 31 - Иовлева Анастасия
\subsection{Признак определённости системы линейных уравнений с\\ квадратной матрицей коэффициентов. Формулы Крамера.}
Пусть $A$ — матрица коэффициентов некой СЛУ, в которой количество уравнений равно количеству неизвестных, $\vec b$ — вектор правых частей, $\vec x$ — вектор неизвестных, матрицы $A_i$ получены из $A$ заменой в них $i$-ого столбца на $\vec b$.

\begin{que31theorem}
Если $\det A \not= 0$, то СЛУ имеет единственное решение, которое может быть найдено по формулам 
$$
x_i = \frac{\det A_i}{\det A}.
$$ 
Эти формулы называются формулами Крамера.
\end{que31theorem}

\begin{proof}
При любом элементарном преобразовании СЛУ в матрицах $A$ и $A_i$ одновременно происходит соотвествующее элементарное преобразование строк и, следовательно, отношения, стоящие в правых частях формул Крамера, не изменяются. С помощью элементарных преобразований строк матрицу $A$ можно привести к единичной, поэтому достаточно доказать теорему для случая, когда $A = E$.

Если $A = E$, то система имеет вид:
\begin{gather*}
\begin{cases*}
x_1 = b_1 \\
x_2 = b_2 \\
\dots \\
x_n = b_n
\end{cases*}
\end{gather*}
Она, очевидно, имеет единственное решение $x_i = b_i$.

С другой стороны,
\begin{gather*}
\det A = \det E = 1,\ \ \det A_i = 
\begin{vmatrix*}
1 & 0 & \dots & b_1 & \dots & 0 & 0\\
0 & 1 & \dots & b_2 & \dots & 0 & 0\\
\hdotsfor{7} \\
0 & 0 & \dots & b_i & \dots & 0 & 0 \\
\hdotsfor{7} \\
0 & 0 & \dots & b_{n-1} & \dots & 1 & 0 \\
0 & 0 & \dots & b_n & \dots & 0 & 1
\end{vmatrix*} = b_i,
\end{gather*}
так что формулы Крамера в этом случае действительно верны.
\end{proof}

% 32 - Попов Никита
\subsection{Элементарные преобразования строк матрицы, их обратимость и реализация при помощи умножения матриц.}
Элементарными преобразованиями строк матрицы называют:

\begin{enumerate}
    \item
        прибавление к любой строке матрицы другой, умноженной на ненулевое число.
    \item
        перестановку местами любых двух строк матрицы;
    \item
        умножение любой строки матрицы на константу $k, k \neq 0$ (при этом определитель матрицы увеличивается в k раз);
\end{enumerate}

Каждому элементарному преобразованию соответствует \emph{элементарная матрица} --- матрица, при умножении на которую справа матрицы $A$, результат будет равен матрице после преобразования. Такие матрицы получаются после применения соответствующего преобразования к единичной матрице.

\[
    U_{i,j,\lambda} =
    \begin{pmatrix}
        1       &0      &\ldots &0      &\ldots &0      &\ldots &0\\
        0       &1      &\ldots &0      &\ldots &0      &\ldots &0\\
        \vdots  &\vdots &\ddots &\vdots &\ddots &\vdots &\ddots &\vdots\\
        0       &0      &\ldots &1      &\ldots &\lambda&\ldots &0\\
        \vdots  &\vdots &\ddots &\vdots &\ddots &\vdots &\ddots &\vdots\\
        0       &0      &\ldots &0      &\ldots &1      &\ldots &0\\
        \vdots  &\vdots &\ddots &\vdots &\ddots &\vdots &\ddots &\vdots\\
        0       &0      &\ldots &0      &\ldots &0      &\ldots &1\\
    \end{pmatrix}
\]
Из определения произведения матриц вытекает, что она выполняет элементарное преобразование --- все строки, кроме $i$ не меняются; $A_{(i)}$ становится равна $A_{(1)} + A_{(j)}\cdot \lambda$.
\[
    U_{i,j} =
    \begin{pmatrix}
        1       &0      &\ldots &0      &\ldots &0      &\ldots &0\\
        0       &1      &\ldots &0      &\ldots &0      &\ldots &0\\
        \vdots  &\vdots &\ddots &\vdots &\ddots &\vdots &\ddots &\vdots\\
        0       &0      &\ldots &0      &\ldots &1      &\ldots &0\\
        \vdots  &\vdots &\ddots &\vdots &\ddots &\vdots &\ddots &\vdots\\
        0       &0      &\ldots &1      &\ldots &0      &\ldots &0\\
        \vdots  &\vdots &\ddots &\vdots &\ddots &\vdots &\ddots &\vdots\\
        0       &0      &\ldots &0      &\ldots &0      &\ldots &1\\
    \end{pmatrix}
\]
Из определения произведения матриц вытекает, что она выполняет элементарное преобразование. В самом деле, все строки, кроме $i$ и $j$ не меняются; $A_{(i)}$ становится равна $A_{(j)}\cdot 1$, и наоборот.
\[
    U_{i, \lambda} =
    \begin{pmatrix}
        1       &0      &\ldots &0      &\ldots &0\\
        0       &1      &\ldots &0      &\ldots &0\\
        \vdots  &\vdots &\ddots &\vdots &\ddots &\vdots\\
        0       &0      &\ldots &\lambda&\ldots &0\\
        \vdots  &\vdots &\ddots &\vdots &\ddots &\vdots\\
        0       &0      &\ldots &0      &\ldots &1\\
    \end{pmatrix}
\]
Выполнение этого свойства вытекает из принципов умножения на диагональную матрицу.

Назовём две матрицы \emph{эквивалентными} (обозначение $A\sim B$), если $B$ можно получить из $A$ с помощью элементарных преобразований.

Очевидно, что если $A\sim B,\ B\sim C$, то $A\sim C$.
\begin{proposal}
    $A\sim B \iff B\sim A$:
\end{proposal}
\begin{proof}
    Если $B$ получается из $A$ одним элементарным преобразованием, то придумать обратное несложно:
    \begin{enumerate}
        \item $B = A\cdot U_{i,j,\lambda}$. Тогда обратное действие --- $A = B\cdot U_{i, j, -\lambda}$
        \item $B = A\cdot U_{i,j}$. Тогда обратное действие --- $A = B\cdot U_{i, j}$
        \item $B = A\cdot U_{i,\lambda}$. Тогда обратное действие --- $A = B\cdot U_{i, \lambda^{-1}}$
    \end{enumerate}
\end{proof}

% 33 - Иовлева Анастасия
\subsection{Ступенчатый и улучшенный ступенчатый вид матрицы. Теорема о приведении матрицы к ступенчатому и улучшенному ступенчатому виду при помощи элементарных преобразований строк.}
\textit{Ведущий элемент} ненулевой строки — ее первый ненулевой элемент.

Матрица называется \textit{ступенчатой}, или имеющей \textit{ступенчатый вид}, если:
\begin{enumerate}
\item номера ведущих элементов строк строго возрастают;
\item все нулевые строки стоят в конце (внизу).
\end{enumerate}

Пример ступенчатой матрицы:
\[
\begin{pmatrix}
0 & 5 & a_0 & a_1 & a_2 & a_3 \\
0 & 0 &   0 &   2 & a_4 & a_5 \\
0 & 0 &   0 &   0 &   1 & a_6 \\
0 & 0 &   0 &   0 &   0 &   0
\end{pmatrix}
\]

Матрица называется \textit{улучшенной ступенчатой}, или \textit{канонической}, если:
\begin{enumerate}
\item она имеет ступенчатый вид;
\item все ведущие элементы равны 1 и это единственный ненулевой элемент в столбцах, где они стоят.
\end{enumerate}

Пример канонической матрицы:
$$
\begin{pmatrix*}
0 & 1 & 	0 & a_{13} & 0 & 0 & a_{16}\\
0 & 0 & 	1 & a_{23} & 0 & a_{25} & a_{26}\\
0 & 0 &		0 & 	 0 & 1 & 0 & a_{36}\\
0 & 0 & 	0 & 	 0 & 0 & 0 & 	  0
\end{pmatrix*}
$$

\begin{que33theorem}
Всякую матрицу элементарными преобразованиями строк можно привести к ступенчатому виду, а всякую ступенчатую можно привести к канонической. 
\end{que33theorem}

\begin{que33cons}
Всякую матрицу элементарными преобразованиями можно привести к канонической.
\end{que33cons}

\begin{proof}
Просто приведем алгоритм такого преобразования. К ступенчатому:
\begin{itemize}
\item[\textbf{Шаг 1}] Если матрица нулевая, то с ней уже ничего делать не надо. Иначе ищем первый ненулевой столбец — пусть он будет под номером $j$.
\item[\textbf{Шаг 2}] Если $a_{1j} \neq 0$, то переходим к следующему шагу. Иначе ищем такое $k$, что $a_{kj} \neq 0$ и меняем первую и $k$-ую строки.
\item[\textbf{Шаг 3}] Имеем $a_{1j} \neq 0$. Вычитая первую строку с нужным коэффициентом из всех остальных срок, добиваемся того, чтобы снизу стояли все нули: $a_{ij} = 0,\ \ \forall i \in \{2, \ldots, n\}$.
\item[\textbf{Шаг 4}] Повторяем алгоритм для последующих строк, на этот раз вытаскивая ведущий элемент (шаг 2) на вторую строку, третью и так далее, пока не приведем к ступенчатому виду.
\end{itemize}

К каноническому:
\begin{itemize}
\item Начинаем с нижней строки. Делим ее на ведущий элемент, от чего он становится равен 1, а потом вычитаем строку с нужным коэффициентом из вышестоящих строк так, чтобы над ведущими элементами стояли нули. Переходим к следующей строке и повторяем, пока не получим каноническую.
\end{itemize}
\end{proof}


% 34 - Сухова Ольга
\subsection{Расширенная матрица системы линейных уравнений. Эквивалентные системы линейных уравнений. Поведение множества решений системы линейных уравнений при элементарных преобразованиях строк её расширенной матрицы.}

\textit{Матричная форма записи СЛУ} --- $A\vec{x}=\vec{b}$, где 
\begin{gather*}
A = \begin{pmatrix}
a_{11} & a_{12} & \ldots & a_{1n} \\
a_{21} & a_{22} & \ldots & a_{2n} \\
\vdots & \vdots & \ddots & \vdots \\
a_{m1} & a_{m2} & \ldots & a_{mn} \\
\end{pmatrix}
\text{--- \textit{матрица коэффициентов},} \\
\vec{b} = \begin{pmatrix}
b_{1} \\
b_{2} \\
\vdots \\
b_{m} \\
\end{pmatrix} \text{--- \textit{столбец правых частей},} \\
\vec{x} = \begin{pmatrix}
x_{1} \\
x_{2} \\
\vdots \\
x_{m} \\
\end{pmatrix} \text{--- \textit{столбец неизвестных}.}
\end{gather*}

\textit{Расширенная матрица СЛУ} — матрица, которая имеет вид:
\[
\begin{pmatrix}
a_{11} & a_{12} & \ldots & a_{1n} & b_{1} \\
a_{21} & a_{22} & \ldots & a_{2n} & b_{2}\\
\vdots & \ldots & \ddots & \ddots & \vdots \\
a_{m1} & \ldots & \ldots & a_{mn} & b_{m}\\
\end{pmatrix}
\] 
и содержит всю информацию о СЛУ. 

Две СЛУ \textit{эквивалентны} если имеют одинаковое множество решений. 

\begin{que34theorem}
Всякое элементарное преобразование строк матрицы переводит СЛУ в эквивалентную.
\end{que34theorem}

\begin{proof}
Пусть СЛУ $(A | \vec{b} )$ с множеством решений $S\subset R^{n}$.
Пусть СЛУ $(A'|\vec{b'})$ с множеством решений  $S'\subset R^{n}$.
Если  $(A'|\vec{b'})$ получена из  $(A | \vec{b} )$ при помощи одного элементарного преобразования, то $S \subseteq S'$. Но от  $(A'|\vec{b'})$ к $(A | \vec{b} )$ можно перейти при помощи элементарных преобразований, т.к. все преобразования строк обратимы. А значит, $ S'\subseteq S $, а тогда $S=S'$.
\end{proof}

% 35 - Хайдуров Руслан
\subsection{Метод Гаусса решения систем линейных уравнений. Число решений системы линейных уравнений с действительными коэффициентами.}
Вспомним, что элементарные преобразования над расширенной матрицей СЛУ переводят ее в эквивалентную. Тогда приведем ее к ступенчатому виду — это будет называться \textit{прямым ходом метода Гаусса}. Остаётся только описать множество решений системы, матрица которой является ступенчатой.

Если в полученной матрице есть строка вида $\left(0,0,\dots,0|b\right)$, то система несовместна. Ведь действительно, у уравнения $0x_1 + 0x_2 + \dots + 0x_n = b$ нет решений, если $b \neq 0$. Иначе система совместна.

В случае совместной системы возможны еще два варианта — когда количество ненулевых строк равно количеству неизвестных, и когда оно меньше. 

Если ненулевых строк столько же, сколько неизвестных, то после отбрасывания нулевых строк получится строго треугольная система. Можно привести ее к каноническому виду (применить \textit{обратный ход метода Гаусса}), тогда $i$-ое уравнение СЛУ будет иметь вид $x_i = b'_i$, где $b'_i$ получена из $b_i$ в процессе преобразований. Тогда, очевидно, система имеет единственное решение — она определенная. 

Теперь пусть ненулевых строк меньше, чем неизвестных. Тогда назовем \textit{главными} те неизвестные, коэффициенты при которых являются лидерами строк, а остальные назовем \textit{свободными}. Отбросив нулевые строки и перенеся члены со свободными неизвестными в правую часть, мы снова получим строго треугольную систему. Решая ее как в предыдущем случае, находим выражение главных неизвестных через свободные. Подставляя в свободные любые значения, получаем бесконечное количество решений — система будет неопределенной.

Следствия:
\begin{itemize}
\item СЛУ определённа тогда и только тогда, когда все неизвестные главные.
\item Если неизвестных в СЛУ больше, чем уравнений, то система является неопределённой.
\end{itemize}

% 36 - Хачиянц Алексей
\subsection{Однородные системы линейных уравнений. Существование ненулевого решения у однородной системы линейных уравнений с числом неизвестных, большим числа уравнений. Связь между множествами решений системы линейных уравнений и соответствующей однородной системы.}
\textit{Однородной СЛУ} называют уравнение вида $A\vec{x} = \vec{0}$, где $A$ --- матрица коэффициетов, $\vec{x}$ --- вектор неизвестных:
\[\begin{cases}
a_{11}x_1 + a_{12}x_2 + \ldots + a_{1n}x_n = 0 \\
a_{21}x_1 + a_{22}x_2 + \ldots + a_{2n}x_n = 0 \\
\dotfill \\
a_{m1}x_1 + a_{m2}x_2 + \ldots + a_{mn}x_n = 0 \\
\end{cases}\]

Очевидно, что эта система всегда совместна, так как есть нулевое решение $\vec{x} = \vec{0}$.

Пусть в системе переменных больше, чем уравнений (строк матрицы СЛУ). Тогда в ступенчатом виде будет хотя бы одна свободная неизвестная ($x_r$). Значит, есть решение с $x_r \neq 0$. Тогда у СЛУ бесконечно много решений, среди которых есть ненулевые.

Пусть задана система система линейных уравнений $A\vec{x} = \vec{b}$, где $\vec{b} = (b_1, b_2, \ldots, b_n)$.

\textbf{Предложение 1}: \textit{Если сложить решение неоднородной системы с решением связанной с ней однородной, то получится решение неоднородной системы.}
\begin{proof}
Пусть $(\alpha_1, \alpha_2, \ldots, \alpha_n)$ --- решение уравнения $A\vec{x} = \vec{b}$ и $(\beta_1, \beta_2, \ldots, \beta_n)$ --- решения уравнения $A\vec{x} = \vec{0}$. Тогда рассмотрим $i$-ые строки:
\begin{gather*}
\begin{cases}
a_{i1}\alpha_1 + a_{i2}\alpha_2 + \ldots + a_{in}\alpha_n = b_i \\
a_{i1}\beta_1 + a_{i2}\beta_2 + \ldots + a_{in}\beta_n = 0 \\
\end{cases}\\
\Downarrow\\
a_{i1}(\alpha_1 + \beta_1) + a_{i2}(\alpha_2 + \beta_2) + \ldots + a_{in}(\alpha_n + \beta_n) = b_i
\end{gather*}
Тогда $(\alpha_1 + \beta_1, \alpha_2 + \beta_2, \ldots, \alpha_n + \beta_n)$ также является решением неоднородной системы.
\end{proof}

\textbf{Предложение 2}: \textit{Разность двух решений неоднородной системы даст решение ассоциированной с ней однородной системы.}
\begin{proof}
Пусть $(\alpha_1, \alpha_2, \ldots, \alpha_n)$ и $(\beta_1, \beta_2, \ldots, \beta_n)$ --- решения уравнения $A\vec{x} = \vec{b}$. Тогда рассмотрим $i$-ю строку:
\begin{gather*}
\begin{cases}
a_{i1}\alpha_1 + a_{i2}\alpha_2 + \ldots + a_{in}\alpha_n = b_i \\
a_{i1}\beta_1 + a_{i2}\beta_2 + \ldots + a_{in}\beta_n = b_i \\
\end{cases}\\
\Downarrow\\
a_{i1}(\alpha_1 - \beta_1) + a_{i2}(\alpha_2 - \beta_2) + \ldots + a_{in}(\alpha_n - \beta_n) = 0
\end{gather*}
Тогда $(\alpha_1 - \beta_1, \alpha_2 - \beta_2, \ldots, \alpha_n - \beta_n)$ является решением однородной системы.
\end{proof}

\textbf{Теорема}: \textit{Пусть $c$ --- какое-то решение неоднородной системы, а $L$ --- множество всех решений связанной с ней однородной системы. Тогда $c + L$ есть множество всех решений неоднородной системы.}
\begin{proof}
Пусть $M$ --- множество всех решений данной неоднородной СЛУ и ${c \in M}$. Каждый элемент множества $c + L$ можно представить в виде $c + l,\; l \in L$. Но согласно предложению 1 $c + l \in M$. Тогда $c + L \subset M$.

При этом верно, что $M \subset c + L$. Действительно, пусть $d \in M$. Тогда $d - c \in L$ по предложению 2, следовательно $d \in c + L$ и $M \subset c + L$. Но тогда $M = c + L$.
\end{proof}

\textit{Геометрический смысл}: множество $M$ есть сдвиг множества $L$ в $\mathbb{R}^n$.

% 37 - Беляков Денис
\subsection{Вычисление обратной матрицы при помощи элементарных преобразований.}
\begin{proposal}
Пусть $A \in \Mat_n$.
Рассмотрим матрицу $M = (A|E) \in \Mat_{n \times 2n}$.\\
Пусть $M' = (K|B)$ -- матрица, полученная из $M$ с помощью элементарных преобразований строк, причем $K$ -- канонический вид матрицы $A$.
Тогда $A$ невырожденна (обратима) тогда и только тогда, когда $K=E$, при этом $B = A^{-1}$. 
\end{proposal}
\begin{proof}
Вспомним, что для невырожденной матрицы верно, что $\det A \neq 0$. Так как элементарные преобразования не могут обнулить определитель, то и $\det K \neq 0$.

Итого, $K$ — улучшенный ступенчатый вид матрицы $A$ и при этом у нее не нулевой определитель. Единственная такая матрица — единичная, то есть $K = E$ ($K$ верхнетреугольна, поэтому ее определитель есть произведение диагональных элементов. Но если в $K$ есть «ступеньки» длины больше двух, то на диагонали есть нули, а значит и $\det K = 0$).

Элементарные преобразования строк --- результат умножения слева на элементарную матрицу. Так как в итоге из $A$ мы получили $E$, то $E = U_s \cdot \ldots \cdot U_2 \cdot U_1 \cdot A$. Домножив справа на обратную, получим, что $A^{-1} = U_s \cdot \ldots \cdot U_2 \cdot U_1$.

Но все эти операции применялись ко всей матрице $M = (A|E)$, из которой в итоге получилась $M' = (E|B)$. То есть те же самые операции перевели $E$ в $B$. Тогда $B = (U_s \cdot \ldots \cdot U_2 \cdot U_1 \cdot E) = U_s \cdot \ldots \cdot U_2 \cdot U_1 = A^{-1}$.
\end{proof}

% 38 - Вельдяйкин Николай
\subsection{Векторные пространства. Примеры. Простейшие следствия из аксиом.}
Множество $V$ называется \textit{векторным (линейным) пространством} над полем $\mathbb{R}$, если на $V$ заданы следующие операции:

\begin{enumerate}
\item Сложение векторов: $V \times V \rightarrow V : (\vec{a},\vec{b}) \mapsto \vec{a}+\vec{b}$;
\item Умножение вектора на скаляр: $\mathbb{R} \times V \rightarrow V : (\lambda , \vec{a}) \mapsto \lambda\vec{a}$,
\end{enumerate}
для которых верны следующие \textit{аксиомы векторного пространства:}
\begin{enumerate}
\item $\forall\,\vec{a}, \vec{b} \in V\; \vec{a} + \vec{b} = \vec{b} + \vec{a}$ --- коммутативность
\item $\forall\,\vec{a}, \vec{b}, \vec{c} \in V\; (\vec{a} + \vec{b}) + \vec{c} = \vec{a} + (\vec{b} + \vec{c})$ --- ассоциативность
\item $\exists\,\vec{0} \in V : \forall\,\vec{a} \in V\; \vec{0} + \vec{a} = \vec{a} + \vec{0} = \vec{a}$ --- существование нулевого вектора. Замечание: $\vec{a} + (-\vec{b})$ обычно пишут, как $\vec{a} - \vec{b}$
\item $\forall\,\vec{a} \in V \exists -\vec{a} \in V : (-\vec{a}) + \vec{a} = \vec{a} + (-\vec{a}) = \vec{0}$ --- существование противоположного вектора
\item $\forall\,\vec{a} \in V\; 1\vec{a} = \vec{a}$ --- умножение на единичный скаляр
\item $\forall \lambda, \mu \in \mathbb{R}; \vec{a} \in V\; (\lambda\mu)\vec{a} = \lambda(\mu\vec{a})$ --- ассоциатвность умножения на скаляр
\item $\forall \lambda, \mu \in \mathbb{R}; \vec{a} \in V\; (\lambda + \mu)\vec{a} = \lambda\vec{a} + \mu\vec{a}$ --- дистрибутивность умножения относительно сложения
\item $\forall \lambda \in \mathbb{R}; \vec{a}, \vec{b} \in V\; \lambda(\vec{a} + \vec{b}) = \lambda \vec{a} + \lambda \vec{b}$ --- дистрибутивность сложения относительно умножения
\end{enumerate}

Также стоит понимать, что вместо $\mathbb{R}$ можно подставить любое другое поле.

\

Примеры векторных пространств над $\mathbb{R}$ с введёнными операциями сложения и умножения на скаляр:
\begin{enumerate}
\item $V = \{\vec{0}\}$ 
\item $\mathbb{R}$
\item $\mathbb{R}^n$ (реализованное как пространство строк или стобцов)
\item $\Mat_{n \times m}$ (то же самое, что $\mathbb{R}^{nm}$)
\item Множество функций $f: M \mapsto \mathbb{R}$, где $M$ --- произвольное (но фиксированное) множество.
Частный случай: $M = [0,1]$.
\end{enumerate}


\textbf{Простейшие следствия из аксиом:}
\begin{enumerate}
\item Нулевой элемент единствен.
\begin{proof}
Пусть $\vec{0}_1$ и $\vec{0}_2$ --- два нуля. Тогда $\vec{0}_1 = \vec{0}_1 + \vec{0}_2 = \vec{0}_2$.
\end{proof}
\item Противоположный элемент единствен.
\begin{proof}
Пусть $-\vec{a}_1$ и $-\vec{a}_2$ --- два противоположных к $\vec{a}$ элемента. Тогда $-\vec{a}_1 = -\vec{a}_1 + \vec{0} = -\vec{a}_1 + \vec{a} - \vec{a}_2 = \vec{0} -\vec{a}_2 = -\vec{a}_2$.
\end{proof}
\item $\forall\,\lambda \in \mathbb{R}\; \lambda\vec{0} = \vec{0}$
\begin{proof}
$\lambda\vec{0} = \lambda(\vec{0} + \vec{0}) = \lambda\vec{0} + \lambda\vec{0} \iff \lambda\vec{0} = \vec{0}$
\end{proof}
\item $\forall\,\lambda \in \mathbb{R}\;\lambda(-\vec{a}) = -\lambda\vec{a}$
\begin{proof}
$\lambda(-\vec{a}) + \lambda\vec{a} = \lambda((-\vec{a} + \vec{a})) = \lambda\vec{0} = \vec{0}$
\end{proof}
\item $0\vec{a} = \vec{0}$
\begin{proof}
$0\vec{a} = (0 + 0)\vec{a} = 0\vec{a} + 0\vec{a} \iff 0\vec{a} = \vec{0}$
\end{proof}
\item $(-1)\vec{a} = (-\vec{a})$
\begin{proof} См. следствие 4 при $\lambda = 1$. \end{proof}
\end{enumerate}

% 39 - Гринберг Вадим
\subsection{Подпространства векторных пространств. Структура множества решений однородной системы линейных уравнений.}
Пусть $V$ --- векторное пространство.

\textbf{Определение:} Подмножество векторов $U \subseteq V$ --- \textit{подпространство}, если:
\begin{enumerate}
  \item $\vec{0} \in U$
  \item $\vec{a} \in U, \vec{b} \in U \Rightarrow \vec{a} + \vec{b} \in U$
  \item $\vec{a} \in U, \lambda \in \bbR \Rightarrow \vec{\lambda a} \in U$
\end{enumerate}

\begin{proposal}
Всякое подпространство $U$, принадлежащее векторному пространству $V$, само явялется векторным пространством относительно имеющихся в $V$ операций.
\end{proposal}
\begin{proof}
Проверка всех аксиом векторного пространства --- они выполняются и в подпространстве.
\end{proof}
Примеры:

\begin{enumerate}
  \item $\vec{0}$ и само пространство $V$  --- подпространства в $V$.
  \item Множество диагональных, множество верхнетреугольных матриц, множество нижнетреугольных матриц в $M_n$ --- все эти множества являются подпространствами в $M_n$.
\end{enumerate}

\begin{proposal}
Множество решений всякой однородной СЛУ $A\vec{x} = \vec{0}$, где $A \in Mat_{m\times n}$ и $\vec{x} \in \bbR^n$, является подпространством в $\bbR^n$.
\end{proposal}
\begin{proof}
Пусть $S \subseteq \bbR^n$ --- множество решений нашей однородной СЛУ. Тогда просто проверим выполнение всех условий подпространства:

\begin{enumerate}
  \item $\vec{0} \in S$, т.к. $A\vec{0} = \vec0$, то есть нуль-вектор всегда является решением.
  \item $\vec{x_1}, \vec{x_2} \in S \Rightarrow A(\vec{x_1} + \vec{x_2}) = A\vec{x_1} + A\vec{x_2}  = 0$, то есть сумма решений тоже является решением.
  \item $\vec{x} \in S, \lambda \in R \Rightarrow A\vec{\lambda x} = \lambda A\vec{x} = 0$, то есть решение, умноженное на скаляр, тоже является решением.
\end{enumerate}
\end{proof}

% 40 - Иовлева Анастасия
\subsection{Линейные комбинации векторов. Линейная оболочка подмножества векторного пространства. Конечномерные векторные пространства.}
Линейная комбинация конечного набора векторов векторного пространства --- всякий вектор $\vec v =  \lambda_1\vec{a_1} + \lambda_2\vec{a_2} + \ldots + \lambda_n\vec{a_n}, \lambda_1, \lambda_2, \ldots, \lambda_n \in \mathbb{R}$. 

Линейная комбинация $\lambda_1 a_1 + \lambda_2 a_2 + \dots + \lambda_n a_n$ называется \textit{тривиальной}, если $\lambda_i = 0 \ \ \forall i$, и \textit{нетривиальной} в противном случае.

Пусть $S \subseteq V$ — какое-то подмножество. Совокупность всевозможных (конечных) линейных комбинаций векторов из $S$ называется \textit{линейной оболочкой} множества $S$ и обозначается через $\langle S \rangle$. Это наименьшее подпространство пространства $V$, содержащее $S$. Говорят, что пространство $V$ \textit{порождается} множеством $S$, если $\langle S \rangle = V$.

Векторное пространство называется \textit{конечномерным}, если оно порождается конечным числом векторов, и \textit{бесконечномерным} в противном случае.

\begin{que40suggest}
Линейная оболочка подмножества $S$ векторного пространства $V$ является подпространством этого векторного пространства.
\end{que40suggest}

\begin{proof}
Чтобы доказать, что линейная оболочка является подпространством, достаточно показать, что выполняются его свойства.
\begin{itemize}
\item Ноль лежит в линейной оболочке.
$$v_1, \ldots, v_n \in S, \ \ 0 \cdot v_1 + \ldots + 0 \cdot v_n = 0 \in \langle S \rangle \rightarrow 0 \in \langle S \rangle
$$
\item Сумма двух линейных комбинаций лежит в линейной оболочке.
\begin{gather*}
v_1, \ldots, v_n, w_1, \ldots, w_m \in S, \ \ x_1, \ldots. x_n, y_1, \ldots, y_m \in \bbR \Rightarrow \\
\Rightarrow x_1v_1 + \ldots + x_nv_n \in \langle S \rangle, \ \  y_1w_1 + \ldots + y_mw_m \in \langle S \rangle \Rightarrow \\
\Rightarrow x_1v_1 + \ldots + x_nv_n + y_1w_1 + \ldots + y_mw_m \in \langle S \rangle
\end{gather*}
\item Линейная комбинация, умноженная на скаляр, лежит в линейной оболочке.
\begin{gather*}
v_1, \ldots, v_n \in S, \ \ x_1, \ldots, x_n \in \bbR \Rightarrow x_1v_1 + \ldots x_nv_n \in \langle S \rangle \\
\lambda \in \bbR \rightarrow \lambda x_1 v_1 + \ldots + \lambda x_n v_n \in \langle S \rangle
\end{gather*}
\end{itemize}
\end{proof}

\textbf{Примеры}
\begin{itemize}
\item $\langle \vec{0} \rangle = \{0\}$
\item $\vec{a} \in \bbR^2\setminus\{0\} \Rightarrow \langle \vec{a} \rangle = \{\lambda \vec{a}| \forall \lambda \in \bbR \}$ — прямая, содержащая $\vec{a}$.
\item $e_1, \ldots, e_n \in \bbR^n$, где 
\begin{gather*}
e_1 = 
\begin{pmatrix}
1 \\
0 \\
\vdots \\
0
\end{pmatrix}, \ \ 
e_2 = 
\begin{pmatrix}
0 \\
1 \\
\vdots \\
0
\end{pmatrix}, \ \ \ldots, \ \  
e_n = 
\begin{pmatrix}
0 \\
0 \\
\vdots \\
n
\end{pmatrix}.
\end{gather*}
Тогда $\langle e_1, \ldots, e_n \rangle = \bbR^n$, так как
\begin{gather*}
\begin{pmatrix}
x_1 \\
x_2 \\
\vdots \\
x_n
\end{pmatrix} = x_1e_1 + x_2 e_2 + \ldots + x_n e_n.
\end{gather*}
\end{itemize}

\begin{note}
Говорят, что:
\begin{itemize}
\item $\langle S \rangle$ — подпространство, натянутое на $S$;
\item $\langle S \rangle$ — подпространство, порождаемое множеством $S$.
\end{itemize}
\end{note}

% 41 - Попов Никита
\subsection{Линейно зависимые и линейно независимые системы векторов. Критерий линейной зависимости.}
\emph{Линейная зависимость} --- свойство, которое может иметь система векторов. При линейной зависимости существует нетривиальная линейная комбинация векторов, равная нулю: существуют такие $\lambda_1, \ldots, \lambda_n$ (где есть хотя бы один ненулевой элемент), что $\lambda_1a_1 + \lambda_2a_2 + \ldots + \lambda_na_n = 0$. Соответственно, система векторов линейно независима тогда, когда существует только тривиальная линейная зависимость, равная нулю: $\lambda_1a_1 + \lambda_2a_2 + \ldots + \lambda_n a_n = 0$ только при $\lambda_1= \ldots= \lambda_n = 0$.

Другая форма этого определения --- назовём систему векторов линейно зависимой, если хотя бы один из векторов, входящих в эту систему, можно представить в виде линейной комбинации прочих (\textit{критерий линейной зависимости}). Иными словами, существуют такие $\lambda_1, \ldots, \lambda_n$ (где есть хотя бы один ненулевой элемент), что $a_i = \lambda_1a_1 + \ldots + \lambda_{i-1}a_{i-1} + \lambda_{i+1}a_{i+1} + \ldots + \lambda_na_n$.

Доказать эквивалентность этих определений несложно:

\vspace{0.5cm}
$(1)\Rightarrow(2)$: $a_1 = -\frac{\lambda_2}{\lambda_1}a_2 - \frac{\lambda_3}{\lambda_1}a_3 - \ldots - \frac{\lambda_n}{\lambda_1}a_n$

$(2)\Rightarrow(1)$: $0 = -\lambda_1a_1 - \ldots - \lambda_{i-1}a_{i-1} + a_1 - \lambda_{i+1}a_{i+1} - \ldots - \lambda_na_n$


% 42 - Пузырёв Дмитрий
\subsection{Основная лемма о линейной зависимости.}
\begin{linear}
Возьмём $a_1, a_2, \ldots ,a_r$ и $b_1, b_2, \ldots ,b_s$ --- две системы векторов, причём $r < s$. Пусть вторая система линейно выражается через первую, то есть $b_i \in \langle a_1, a_2, \ldots , a_r \rangle \forall i \in \{1, \ldots , s\}$. Тогда система $b_1, b_2, \ldots ,b_s$ линейно завсисима.
\end{linear}
\begin{proof}
Исходя из условия, можно записать:
\[b_i = \alpha_{1i}a_1 + \ldots + \alpha_{ri}a_r,\   i \in \{ 1, \ldots ,s\}
\]

Для произвольных коэффициентов $\lambda_1, \ldots, \lambda_s$ запишем:
\[\lambda_1 b_1 + \ldots + \lambda_s b_s = \lambda_1(\alpha_{11}a_1 + \ldots + \alpha_{r1}a_r) + \ldots + \lambda_s(\alpha_{1s}a_1 + \ldots + \alpha_{rs}a_r) = \]
\[= (\alpha_{11}\lambda_1 + \ldots + \alpha_{1s}\lambda_s)a_1 + \ldots + (\alpha_{r1}\lambda_1 + \ldots + \alpha_{rs}\lambda_s)a_r\]

Рассмотрим систему линейных уравнений:
\[\begin{cases}
\alpha_{11}\lambda_1 + \ldots + \alpha_{1s}\lambda_s = 0 \\
\alpha_{21}\lambda_1 + \ldots + \alpha_{2s}\lambda_s = 0 \\
\dotfill \\
\alpha_{r1}\lambda_1 + \ldots + \alpha_{rs}\lambda_s = 0 
\end{cases}\]

относительно $\lambda_1, \ldots,\lambda_s$. Она совместна, поскольку в ней $r$ уравнений и $s$ неизвестных, а $r < s$ по условию. Также из этого же следует, что система не является определённой (уравнений меньше, чем неизвестных). Значит, она имеет ненулевое решение. Если найти это ненулевое решение и подставить вместо $\lambda_1, \ldots ,\lambda_s$ в выражение выше, получаем зависимость системы $b_1, \ldots ,b_s$. \end{proof}


% 43 - Сухова Ольга
\subsection{Базис конечномерного векторного пространства. Базис как линейно независимая порождающая система. Стандартный базис в пространстве $\mathbb{R}^n$}
Система векторов $\{e_1, e_2, \ldots, e_n\}$ векторного пространства $V$ называется \textit{базисом} этого векторного пространства, если всякий вектор $\vec{v}$ из этого векторного пространства единственным образом представим в виде линейной комбинации векторов ${e_{1}, \ldots, e_{n}}$:
\[\vec{v} = x_1 e_1 + x_2 e_2 + \ldots + x_n e_n, \text{ где $x_1, x_2, \ldots, x_n$ — координаты вектора $\vec{v}$ в базисе $\{e_1, \ldots, e_n\}$}\]

Рассмотрим векторное пространство $\mathbb{R}^n$. Вектора
\[e_1 = \begin{pmatrix} 1 \\ 0 \\ \vdots \\ 0 \end{pmatrix},
e_2 = \begin{pmatrix} 0 \\ 1 \\ \vdots \\ 0 \end{pmatrix}
, \ldots, 
e_n = \begin{pmatrix} 0 \\ 0 \\ \vdots \\ 1 \end{pmatrix}\]
образуют в нём \textit{стандартный} базис.


\begin{base_44}
Система векторов $S = \{e_1, e_2, \ldots, e_n\}$ является базисом в $V$ тогда и только тогда, когда $\langle S \rangle = V$ и $S$ линейно независима.
\end{base_44}
\begin{proof} Докажем следствия в одну и другую стороны:
\begin{itemize}
\item[{$[\Rightarrow]$}] Пусть $\{e_1, e_2, \ldots, e_n\}$ --- базис в $V$. Из определения базиса и линейной оболочки следует, что любой вектор из $V$ линейно выражается единственным образом через векторы из $S$, то есть $V = \langle S \rangle$. При этом из определения базиса следует линейная независимость $e_1, e_2, \ldots, e_n$.

\item[{$[\Leftarrow]$}] Так как $V = \langle S \rangle = \langle e_1, e_2, \ldots, e_n \rangle$, то для любого вектора $\vec{v} \in V$ найдутся скаляры $x_1, x_2, \ldots, x_n$ такие, что $\vec{v} = x_1e_1 + \ldots + x_ne_n$. Теперь покажем, что такое разложение единственно. Пусть это не так и есть другой набор скаляров $y_1, y_2, \ldots, y_n$ такой, что $\vec{v} = y_1e_1 + \ldots + y_ne_n$. Но тогда существует нетривиальная нулевая комбинация векторов $\{e_1, e_2, \ldots, e_n\}$:
\[(x_1 - y_1)e_1 + (x_2 - y_2)e_2 + \ldots + (x_n - y_n)e_n = 0\]
что противоречит условию линейной независимости. Тогда всякое разложение единственно и $\{e_1, e_2, \ldots, e_n\}$ --- базис в $V$.
\end{itemize}
\end{proof}


% 44 - Хайдуров Руслан
\subsection{Существование базиса у конечномерного векторного пространства. Независимость числа элементов в базисе от выбора базиса. Размерность конечномерного векторного пространства.}

\begin{base_44-cons}
Всякая конечномерная линейно независимая система векторов является базисом своей линейной оболочки (см. предложение 1 предыдущего билета).
\end{base_44-cons}

\begin{base_44}
Из всякой конечной системы $S$ векторов пространства $V$ можно выделить конечную подсистему, являющуюся базисом линейной оболочки $\langle S \rangle$.
\end{base_44}

\begin{proof}
Пусть $S = \{v_1, \dots, v_m\}$. Докажем утверждение индукцией по $m$.

База: $m=1$. Тогда в системе лишь один вектор. Если он нулевой, то в качестве базиса берём пустое множество (в математике принята договорённость, согласно которой $\langle \varnothing \rangle = \vec{0}$. Если не нулевой, то система линейно независима и является базисом.

Теперь пусть $m \geqslant 2$ и утверждение верно для меньших $m$. Если система $S = \{v_1, \dots, v_m\}$ линейно независима, то она уже является базисом $\{v_1, \dots, v_m\}$. Пусть система линейна зависима. Тогда существует вектор $v_i$, который линейно выражается через остальные векторы. Тогда $\langle S \rangle$ совпадает с $\langle S\setminus \{v_i\}\rangle$. Но в $\langle S\setminus \{v_i\}\rangle$ можно выбрать базис по предположению индукции.
\end{proof}

\begin{base_44-cons}
Всякое конечномерное пространство обладает базисом.
\end{base_44-cons}

\begin{proof}
$V$ конечномерно, а значит $\exists v_1, \dots v_m \in V$ такие, что $V = \langle v_1, \dots, v_m\rangle$. Но среди $v_1, \dots v_m$ можно выбрать базис по предложению 2.
\end{proof}

\begin{base_44}
Все базисы конечномерного векторного пространства $V$ содержат одно и то же число элементов. 
\end{base_44}

\begin{proof}
Пусть $e_1, \dots, e_n$ и $e_1', \dots, e_m'$ - два базиса в $V$ и $m>n$. Тогда $e_1', \dots, e_m' \in \langle e_1, \dots e_n\rangle$. Но тогда $e_1', \dots, e_m'$ линейно зависимы по основной лемме о линейной зависимости. Противоречие.
\end{proof}

Размерностью линейного векторного пространства $V$ называется число элементов в базисе $V$. Обозначение: $\dim V$. 

\begin{lemma}
$V$ — векторное пространство, $\dim V = n < \infty$. Если $v_1, \dots, v_m \in V$ — линейно независимые векторы, то $m \leqslant n$.
\end{lemma}

\begin{proof}
Пусть $e_1, \dots, e_n$ — базис в $V$. Тогда $v_1, \dots v_m \in \langle e_1, \dots, e_n\rangle$ по основной лемме о линейной зависимости, а значит $m \leqslant n$.
\end{proof}

% 45 - Хачиянц Алексей
\subsection{Дополнение линейно независимой системы векторов до базиса конечномерного векторного пространства.}
\textbf{Теорема:} \textit{Пусть $V$ --- конечномерное векторное пространство над $\mathbb{K}$ с базисом\\ $(e_1, e_2, \ldots, e_n)$. Тогда верно следующее утверждение: любую систему $f_1, f_2, \ldots, f_s,\ \  s \leqslant n$ линейно независимых векторов можно дополнить до базиса.}
\begin{proof}
Рассмотрим систему векторов $f_1, f_2, \ldots, f_s, e_1, e_2, \ldots, e_n$. Выбросим из этой системы все вектора, линейно выражаемые через предыдущие. Так как $f_1, f_2, \ldots, f_s$ линейно независимы, то ни один из них выброшен не будет, и система будет иметь вид
\[f_1, f_2, \ldots, f_s; e_{i_1}, \ldots, e_{i_t}\]
Любое нетривиальное соотношение
\[\alpha_1 f_1 + \ldots + \alpha_s f_s + \beta_1 e_{i_1} + \ldots + \beta_t e_{i_t} = 0\]
обязательно содержало бы какой-либо коэффициент $\beta_{k} \neq 0$, где $k$ --- максимально (иначе система $f_1, f_2, \ldots, f_s$ была бы линейно зависима). Но тогда $e_{i_k}$ выразился бы через предыдущие вектора, что невозможно. Тогда существует только тривиальная линейная комбинация, дающая ноль.

С другой стороны, все вектора из $V$ линейно выражаются через базис $(e_1, e_2, \ldots, e_n)$ и тем более через систему $f_1, f_2, \ldots, f_s; e_1, e_2, \ldots, e_n$. Тогда линейно независимая система $f_1, f_2, \ldots, f_s; e_{i_1}, \ldots, e_{i_t}$ максимальна. Следовательно, она является базисом, а $e_{i_1}, \ldots, e_{i_t}$ --- искомое дополнение.
\end{proof}

% 46 - Беляков Денис
\subsection{Размерность подпространства конечномерного векторного\\ пространства. Ранг системы векторов конечномерного векторного пространства.}

\begin{theorem46}
Возьмем конечномерное векторное пространство $V$ размерности $n$. Пусть $U \subseteq V$ --- подпространство, тогда 
    \begin{enumerate}
    \item $U$ --- конечномерно и $\dim U \le \dim V$.
    
\begin{proof}
Пусть $u_1 \ldots u_m$ --- максимальная линейно независимая система векторов в $U$ (такая система конечна, т.к. $U \subseteq V$). Тогда, поскольку всякую линейно независимую систему векторов можно дополнить до базиса, $u_1 \ldots u_m$ порождают $U$. Значит, они есть базис в $U$. Следовательно, по лемме о размерности системы векторов в конечномерном векторном пространстве, $m \leqslant n \Rightarrow \dim U \leqslant \dim V$.  
\end{proof}
    
    \item $\dim U = \dim V \iff U=V$.
    
\begin{proof}
Если $U=V$, их размерности равны. Докажем в обратную сторону. Пусть $\dim U=\dim V$, но $U\ne V$, тогда в $U$ есть базис из $n$ векторов и эти же векторы есть базис в $V$, т.к. всякий набор из $n$ линейно независимых векторов $n$-мерного векторного пространства есть его базис. Следовательно, $U=V$.
\end{proof}

    \end{enumerate}
\end{theorem46}



\textit{Рангом} системы векторов $S \subseteq V$ называют число $\rk S$, равное наибольшему числу векторов в линейно независимой подсистеме $S' \subseteq S$.

\begin{proposal}
Пусть $S \subseteq V$, тогда $\rk S=\dim\langle S\rangle$.
    
    \begin{proof}
    Пусть $\rk S=k$ и $v_1 \ldots v_k$ --- линейно независимая подсистема в $S$. Тогда $S \subseteq \langle v_1 \ldots  v_k\rangle$, а поскольку всякую линейно независимую систему векторов можно дополнить до базиса, то $\langle S \rangle = \langle v_1 \ldots  v_k\rangle$. Следовательно, $v_1 \ldots v_k$ --- базис в $S$, а значит $\dim\langle S\rangle=k=\rk S$. 
    \end{proof}

\end{proposal}

\textbf{Свойства ранга}:
\begin{enumerate}
\item Ранг линейно независимой системы совпадает с числом её векторов.
\item Ранг линейно зависимой системы меньше числа её векторов.
\item Ранги эквивалентных систем совпадают -- $S_{1}\sim S_{2}\Rightarrow \rk S_{1} = \rk S_{2}$.
\item Ранг подсистемы не больше ранга системы.
\item Если $S_{1}\subset S_{2}$ и $\rk S_{1}=\rk S_{2}$, то $S_{1}$ и $S_{2}$ имеют общую базу.
\item Ранг системы векторов не изменяется, если в неё добавить вектор, являющийся линейной комбинацией остальных векторов системы.
\item Ранг системы векторов не изменяется, если из неё удалить вектор, являющийся линейной комбинацией остальных векторов.
\end{enumerate}

% 47 - Иовлева Анастасия
\subsection{Столбцовый и строковый ранги матрицы, их поведение при элементарных преобразованиях строк и столбцов.}

\textbf{Определение:} \textit{Рангом (или столбцовым рангом) матрицы} называется число, равное рангу системы столбцов. Обозначение: $\rk A$.

\textbf{Определение:} \textit{Строковым рангом матрицы} называется число, равное столбцовому рангу ее транспонированной матрицы, т.е рангу системы строк. Обозначение: $\rk A^T$.

Системы векторов $\{a_1, \ldots, a_n\}$ и $\{b_1, \ldots, b_m\}$ называются \textit{эквивалентными}, если каждый из векторов $b_j$ линейно выражается через $a_1, \ldots, a_n$, и наоборот, каждый из векторов $a_i$ линейно выражается через $b_1, \ldots, b_m$. Это, очевидно, равносильно совпадению линейных оболочек:
$$
\langle a_1, \ldots, a_n \rangle = \langle b_1, \ldots, b_m \rangle 
$$

\begin{que47theorem1}
Ранг матрицы не меняется при элементарных преобразованиях строк.
\end{que47theorem1}

\begin{proof}
Пусть матрица $B$ получена из матрицы $A$ некоторыми элементарными преобразованиями строк. Рассмотрим систему столбцов матрицы $A$: $A^{\left(1\right)}, \dots, A^{\left(n\right)}$. Рассмотрим их некоторую линейную зависимость $x_1A^{\left(1\right)} + x_2A^{\left(2\right)} + \dots + x_nA^{\left(n\right)} = 0$. Но тогда вектор  $\vec{x} = \left(x_1, \dots, x_n\right)$ является решением СЛУ $A\vec{x} = \vec{0}$. Элементарные преобразования строк над СЛУ переводят ее в эквивалентную, следовательно, $\vec{x}$ также является решением СЛУ $B\vec{x} = \vec{0}$. Тогда в $B$ существует линейная зависимость $x_1B^{(1)} + \ldots + x_nB^{(n)} = 0$. Так как элементарные преобразоавания обратимы, то верно и обратное.

Итого, столбцы матрицы $A$ линейно зависимы тогда и только тогда, когда линейно зависимы столбцы $B$, и наоборот. Следовательно, максимальное количество линейно независимых столбцов в обеих матрицах одинаково — а это и означает, что их ранг равен.
\end{proof}

\begin{que47theorem2}
Ранг матрицы не меняется при элементарных преобразованиях столбцов.
\end{que47theorem2}

\begin{proof}
Пусть матрица $A \in Mat_{m\times n}$ и матрица $B$ получена из нее путем некоторых элементарных преобразований cтолбцов. Тогда $\langle A^{\left(1\right)},\dots, A^{\left(n\right)}\rangle \supseteq \{B^{\left(1\right)},\dots,B^{\left(n\right)}\} \implies \langle A^{\left(1\right)},\dots, A^{\left(n\right)}\rangle \supseteq \langle B^{\left(1\right)},\dots,B^{\left(n\right)}\rangle$. Так как элементарные преобразования обратимы, то справедливо и обратное включение: $\langle B^{\left(1\right)},\dots, B^{\left(n\right)}\rangle \supseteq \langle A^{\left(1\right)},\dots,A^{\left(n\right)}\rangle$. То есть имеем $\langle A^{\left(1\right)},\dots, A^{\left(n\right)}\rangle = \langle B^{\left(1\right)},\dots,B^{\left(n\right)}\rangle$.

Ранг есть размерность подпространства, задающегося линейной оболочкой. Значит, $\rk{A} = \rk{B}$.
\end{proof}

\begin{que47cons}
Строковый ранг матрицы не меняется при элементарных преобразованиях строк или столбцов матрицы $A$. 
\end{que47cons}

% 48 - Гринберг Вадим
\subsection{Столбцовый и строковый ранги матрицы, имеющей улучшенный ступенчатый вид. Связь между строковым и столбцовым рангами произвольной матрицы. Связь ранга квадратной матрицы с её определителем.}
\begin{proposal}
\textit{Если $A \in Mat_{m \times n}$ имеет улучшенный ступенчатый вид, то $\rk A = \rk A^T$, причём оба числа равны количеству ненулевых строк.}
\end{proposal}
\begin{proof}
\[A = \begin{pmatrix}
0 & 1 & * & 0 & * & \ldots & * & 0 & *\\
0 & 0 & 0 & 1 & * & \ldots & * & 0 & *\\
\vdots & \vdots & \vdots & \vdots & \vdots & \ldots & \vdots & \vdots & \vdots\\
0 & 0 & 0 & 0 & 0 & \ldots & 0 & 1 & *\\
0 & 0 & 0 & 0 & 0 & \ldots & 0 & 0 & 0\\
\vdots & \vdots & \vdots & \vdots & \vdots & \ldots & \vdots & \vdots & \vdots\\
0 & 0 & 0 & 0 & 0 & \ldots & 0 & 0 & 0\\
\end{pmatrix}\]

Пусть $r$ --- число ненулевых строк матрицы $A$. Тогда $\{A^{(1)}, \ldots, A^{(n)}\} \supseteq \{e_1, \ldots, e_r\}$, где $e_i$~---~$i$-й вектор стандартного базиса. Но с другой стороны: $\{A^{(1)}, \ldots, A^{(n)}\} \subseteq \langle e_1, \ldots, e_r \rangle$. Следовательно, $\langle A^{(1)}, \ldots, A^{(n)} \rangle = \langle e_1, \ldots , e_r \rangle \Rightarrow \rk A = \dim \langle A^{(1)}, \ldots, A^{(n)} \rangle = \dim \langle e_1, \ldots, e_r \rangle~=~r$.

Теперь покажем, что $\rk A^T = r$.

Ясно, что $\langle A_{(1)}, \ldots, A_{(m)} \rangle = \langle A_{(1)}, \ldots, A_{(r)} \rangle$. Тогда достаточно показать, что $A_{(1)}, \ldots, A_{(r)}$ линейно независимы. 

Пусть $\lambda_1, \ldots, \lambda_r \in \bbR$ таковы, что: $\lambda_1A_{(1)} + \ldots + \lambda_rA_{(r)} = \vec{0}$.

Ограничивая данное соотношение на первый столбец матрицы $A$, получаем:
$$\lambda_1a_{11} + \lambda_2a_{21} + \ldots + \lambda_ra_{r1} = 0 \Rightarrow \lambda_1 \cdot 1 + \lambda_2 \cdot 0 + \ldots + \lambda_r \cdot 0 = 0 \Rightarrow \lambda_1 = 0.$$

Аналогичные равенства получаем для каждого столбца $\Rightarrow \lambda_1 = \lambda_2 = \ldots = \lambda_r = 0 \Rightarrow$ строки $A_{(1)}, \ldots, A_{(r)}$ линейно независимы $\Rightarrow \rk A^T = r$.
\end{proof}

\begin{proposal}
\textit{Для всякой $A \in \Mat_{m \times n}$ имеем: $\rk A = \rk A^T$, причём оба числа равны количеству ненулевых строк в ступенчатом виде, к которому приводится $A$ посредтством элементарных преобразований строк.}
\end{proposal}
\begin{proof}
Так как при переходе от ступенчатого вида к улучшенному ступенчатому число ненулевых строк не изменяется, то утверждение следует из предложений о неизменности ранга матрицы при элементарных преобразованиях.
\end{proof}

\begin{base_44-cons}
Пусть $A \in \mathrm{M}_n$ --- квадратная матрица, тогда:
\begin{enumerate}
\item $\rk A = n \iff \det A \neq 0$
\item $\rk A < n \iff \det A = 0$
\end{enumerate}
\end{base_44-cons}
\begin{proof}
При приведении $A$ к ступенчатому виду $\rk A$ не изменяется, а условия $\det A = 0$ и $\det A \neq 0$ сохраняются. Тогда если в ступенчатом виде есть нулевая строка, то $\rk A < n$ и $\det A = 0$.

Если нет нулевых строк, то $\rk A = n$ и $\det A \neq 0$ (матрица --- верхнетреугольная с ненулевыми элементами на диагонали).
\end{proof}


% 49 - Иовлева Анастасия
\subsection{Подматрицы. Связь рангов матрицы и её подматрицы. \\Миноры. Теорема о ранге матрицы.}
Пусть $A$ — произвольная (не обязательно квадратная) матрица. Всякая матрица, составленная из элементов матрицы $A$, находящихся на пересечениях каких-то выбранных строк и каких-то выбранных столбцов, называется \textit{подматрицей} матрицы $A$. Подчеркнем, что выбираемые строки и столбцы не обязаны идти подряд.

Определитель квадратной подматрицы порядка $k$ называется \textit{минором} порядка $k$ матрицы $A$. Иногда, допуская вольность речи, саму квадратную подматрицу также называют минором. В частности, если $A$ — квадратная матрица порядка $n$, то минор порядка $n-1$, получаемый вычеркиванием $i$-й строки и $j$-го столбца, называется \textit{дополнительным минором} элемента $a_{ij}$ и обозначается через $\bar{M}_{ij}$.

\begin{que49theorem}
Ранг матрицы равен наибольшему порядку ее миноров, отличных от нуля.
\end{que49theorem}

\begin{proof}
Пусть ранг матрицы $A$ равен $r$, и пусть $s > r$. Тогда любые $s$ строк матрицы $A$ линейно зависимы и, тем более, линейно зависимы строки любой квадратной подматрицы порядка $s$, представляющие собой части соответствующих строк матрицы $A$. Следовательно, любой минор порядка $s$ равен нулю. Далее, рассмотрим подматрицу, образованную какими-либо $r$ линейно независимыми строками матрицы $A$. Ее ранг, очевидно, также равен $r$ и, значит, среди ее столбцов найдется $r$ линейно независимых. Минор порядка $r$, образованный этими столбцами, не равен нулю.
\end{proof}

\begin{que49cons}
Ранг матрицы не меньше ранга любой ее подматрицы.
\end{que49cons}

% 50 - Попов Никита
\subsection{Теорема Кронекера-Капелли. Критерий определённости совместной системы линейных уравнений в терминах ранга её матрицы коэффициентов. Критерий определённости системы линейных уравнений с квадратной матрицей коэффициентов.}
\begin{Kroneker}
    Система линейных алгебраических уравнений совместна тогда и только тогда, когда ранг её основной матрицы равен рангу её расширенной матрицы.
\end{Kroneker}
\begin{proof}
    Так как ни ранг матрицы, ни множество решений СЛУ не меняется при элементарных преобразованиях строк, мы можем рассматривать только случай, когда матрица приведена к ступенчатому виду.
    
    В таком случае утверждение ``система совместна'' эквивалентно утверждению ``в матрице нет строк вида $(0,\ldots, 0|x)$, где $x \neq 0$''. Значит, если мы перейдем от матрицы коэффициентов к расширенной матрице для совместной СЛУ, число ненулевых строк не изменится (т.к. не может ни увеличиться, ни уменьшиться добавлением строки вышеуказанного вида).
    Значит, ранги равны.
    
    И наоборот, если система несовместна, то число ненулевых строк, а значит, и ранг, изменятся.
\end{proof}

%Критерии не рассказаны и не доказаны, Никита!
% Бе-бе-бе
\begin{theorem}
    Если СЛУ совместна, то она определена, если ранг матрицы равен числу неизвестных; иначе она имеет бесконечное число решений.
\end{theorem}
\begin{proof}
    Снова будем рассматривать только ступенчатые матрицы, т.к. все прочие можно свести к ступенчатому виду.

    В этом случае, СЛУ определена тогда и только тогда, когда все переменные --- главные; значит, число ступенек равно числу переменных, но так как ранг равен числу ступенек, это эквивалентно утверждению о том, что ранг равен числу переменных.
\end{proof}
\begin{follows}
    Если $A$ --- квадратная матрица, то СЛУ определена тогда и только тогда, когда $\det A \neq 0$.
\end{follows}
\begin{proof}
    Во-первых, из вышедоказанного следует, что если СЛУ определена, то $\det A \neq 0$, (т.к. $\rk A = n \iff \det A \neq 0$).
    
    Во-вторых, если определитель нулю не равен, то ранг равен числу строк и добавление столбца правых частей не может увеличить ранг, т.к. он не больше наименьшей стороны матрицы. Тогда $\rk A = \rk(A|b)$, тогда по теореме Кронекера-Капелли СЛУ совместна, а так как ранг равен числу переменных, решение единственно.
\end{proof}

% 51 - Пузырёв Дмитрий
\subsection{Фундаментальная система решений однородной системы линейных уравнений: определение и метод построения. Размерность пространства решений однородной системы линейных уравнений.}
\textit{Фундаментальной системой решений} однородной системы линйеных уравнений называется базис пространства решений этой системы. Пусть $u_1, u_2, \ldots , u_n$ --- ФСР некой СЛУ. Тогда любое решение этой СЛУ будет единственным образом представимо в виде линейной комбинации:
\[
\lambda_1\vec{u_1} + \lambda_2\vec{u_2} + \ldots + \lambda_n\vec{u_n}
\]
где $\lambda_1, \lambda_2, \ldots ,\lambda_n$ --- произвольные коэффициенты из $\mathbb{R}$.

\textsc{Альтернативное определение по Курошу:} \textit{фундаментальной системой решений} называется всякая максимальная линейно независимая система решений однородной системы линейных уравнений.

Чтобы построить ФСР, удобно воспользоваться следующим свойством: количество векторов в ФСР равно количеству \textit{свободных неизвестных}.

Алгоритм построения следующий: приравнивать каждую свободную неизвестную по очереди к единице, при этом все остальные приравнивать к нулю, подставить значения свободных неизвестных в систему и выразить исходя из этого все зависимые.

\begin{solutions}
Пусть A --- матрица однородной системы линейных уравнений относительно n неизвестных. Тогда множество решений этой системы является подпространством в $\bbR^n$ размерности $n - \rk A$.
\end{solutions}
\begin{proof}
Пусть некоторые решения $\vec x_1, \vec x_2$ принадлежат множеству решений $S$. Значит, $A\vec x_1 = \vec{0}, A\vec x_2 = \vec 0$. Тогда $A(\vec x_1 + \vec x_2) = A\vec x_1 + A\vec x_2 = \vec 0 + \vec 0 = \vec 0$, то есть $\vec x_1 + \vec x_2$ принадлежит множеству решений $S$.

Аналогично показывается принадлежность множеству решений умножения решения на скаляр. Таким образом, множество решений образует векторное пространство.

Приведём матрицу к каноническому виду. Заметим, что пространство решений при элементарных преобразованиях не меняется.
\[\begin{pmatrix}a_{11} & 0 & \ldots & 0 & a_{1,r+1} & \ldots & a_{1,n} \\ 0 & a_{22} & \ldots & 0 & a_{2,r+1} & \ldots & a_{2,n} \\ \vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \\ 0 & 0 & \ldots & a_{rr} & a_{r,r+1} & \ldots & a_{rn} \\ \vdots & \vdots & \ddots & \vdots & \vdots & \ddots & \vdots \end{pmatrix}\]

Поскольку ранг матрицы равен  $r$, то в ней ровно $r$ главных неизвестных. Выразим главные неизвестные через свободные.
\[\begin{cases} x_1 = -\frac{1}{a_{11}}(a_{1,r+1}x_{r+1} + \ldots + a_{1n}x_n) \\
\dotfill \\
 x_r = -\frac{1}{a_{rr}}(a_{r,r+1}x_{r+1} + \ldots + a_{rn}x_n)\end{cases}\]

Из общего решения выделим некоторые частные решения, приравнивая свободные неизвестные к единице. Получим систему из $n-r$ векторов.
\[\begin{cases}u_1 = (\ldots, 1, 0, \ldots , 0) \\
u_2 = (\ldots, 0, 1, \ldots , 0) \\
\dotfill \\
u_{n-r} = (\ldots, 0, 0, \ldots , 1) \end{cases}\]

Докажем, что она образует базис:

\textit{Линейная независимость}: Предположим, что есть такой ненулевой набор скаляров $\lambda_1, \lambda_2, \ldots ,\lambda_{n-r} \in \mathbb{R}$, что $\lambda_1\vec{u_1} + \lambda_2\vec{u_2} + \ldots + \lambda_n\vec{u_{n-r}} = \vec{0}$. Тогда $\forall i \in \{1, \ldots , n - r\} (r + i)$-я координата левой части равна $\lambda_i$, откуда $\lambda_i = 0$. Следовательно, все $\lambda_1 = \lambda_2 = \ldots = \lambda_{n-r} = 0$, значит $u_1, u_2, \ldots , u_{n-r}$ --- линейно независимы (существует только тривиальная их комбинация, равная нулю).

\textit{$\langle u_1, u_2, \ldots , u_{n-r} \rangle$ порождается пространством решений $S$}:
Возьмём некое решение $\vec u \in S$, тогда $\vec u = (\ldots, \lambda_1, \lambda_2, \ldots ,\lambda_{n-r})$. Рассмотрим вектор $\vec v = u - \lambda_1 u_1 - \lambda_2 u_2 - \ldots - \lambda_{n-r} u_{n-r}$. Но тогда $v = (\ldots, 0, 0, \ldots , 0)$, а т.к. значения всех главных неизвестных однозначно определяются значениями свободных, то $v = (0, \ldots, 0, \ldots , 0) = \vec 0$, следовательно $\vec u = \lambda_1 u_1 + \lambda_2 u_2 + \ldots + \lambda_{n-r} u_{n-r}$, значит $u \in \langle u_1, u_2, \ldots , u_{n-r} \rangle \Rightarrow \langle u_1, u_2, \ldots , u_{n-r} \rangle = S$.

Получается, векторы $u_1, u_2, \ldots , u_{n-r}$ действительно состаляют базис в $S$. А из этого следует, что $\dim{S} = n - r = n - \rk A$. 
\end{proof}


% 52 - Сухова Ольга
\subsection{Ортогональное дополнение подмножества в $\mathbb{R}^n$. Связь между ортогональными дополнениями подмножества в $\mathbb{R}^n$ и его линейной оболочки.}

\textit{Ортогональным дополнением} подмножества $S$ в $\mathbb{R}^n$ называется множество
$$
S^{\perp} = \{\vec{x} \in \mathbb{R}^n | (\vec{x},\vec{y})=0\ \  \forall y \in S \},
$$
где $(\vec x, \vec y)$ — скалярное произвдение. Иными словами, $S^{\perp}$ состоит из векторов $\vec{x}$, которые ортогональны векторам из $S$.

\begin{que52lemma1}
$ S \subseteq \mathbb{R}^n \rightarrow S^{\perp} $ подпространство в $\mathbb{R}^n$
\end{que52lemma1}

\begin{proof}
$\vec{y} \in $ S.
\begin{enumerate}
\item $\vec{0} \in S^{\perp}$ так как $(\vec{0},\vec{y})=0$.
\item $\vec{x_{1}},\ \vec{x_{2}} \in S^{\perp},  \rightarrow (\vec{x_{1}}+\vec{x_{2}},\vec{y})=(\vec{x_{1}},\vec{y})+(\vec{x_{2}},\vec{y})=0$.
\item $\vec{x} \in S^{\perp}, \lambda \in \mathbb{R}^n \rightarrow (\lambda \vec{x} , \vec{y}) = \lambda (\vec{x}, \vec{y}) = \lambda 0 = 0.$
\end{enumerate}
\end{proof}

\begin{que52lemma2}
$ S \subseteq \mathbb{R}^n \rightarrow S^{\perp} = \langle S \rangle^{\perp}$
\end{que52lemma2}

\begin{proof}
Так как $S \subseteq \langle S\rangle$, то $\langle S\rangle^{\perp} \subseteq S^{\perp}$.

Пусть $x \in S^{\perp}$. Покажем, что $x \in \langle S\rangle^{\perp}$.

Возьмем произвольный вектор $\vec{y} \in \langle S\rangle$. Тогда $y=\lambda_{1}u_{1}+\dots+\lambda_{k}u_{k}$.
Здесь $\lambda_{i} \in \mathbb{R}$ и $u_{i} \in S$.

Тогда $(\vec{x},\vec{y}) = (\vec{x},\lambda_{1}u_{1} + \dots + \lambda_{k}u_{k})=\lambda_{1}(\vec{x},u_{1}) + \dots + \lambda_{k}(\vec{x},u{k}) = 0$. Следовательно,  $\vec{x}$ ортогонален всем элементам из $\langle S\rangle$, то есть $S^{\perp} \subseteq \langle S\rangle^{\perp}$.

Итого, $S^{\perp} = \langle S\rangle^{\perp}$.
\end{proof}

% 53 - Хайдуров Руслан
\subsection{Размерность ортогонального дополнения подпространства в $\mathbb{R}^n$. Ортогональное дополнение к ортогональному дополнению подпространства в $\mathbb{R}^n$. Подпространства в $\mathbb{R}^n$ и множества решений однородных систем линейных уравнений.}
\begin{lemma}
Пусть $V$ --- подпространство в $\mathbb \bbR^n$. Тогда $\dim V^{\perp} = n - \dim V$. 
\end{lemma}
\begin{proof}
Пусть $v_1, \ldots v_m$ --- базис в $V$. Тогда $V^{\perp} = \{v_1, \ldots, v_m\}^{\perp}$. Рассмотрим матрицу $A \in \Mat_{m \times n}$, где $i$-я строка --- вектор $v_i$. Тогда $V^{\perp}$ --- в точности решение СЛУ $A\vec{x} = \vec{0}$. Следовательно,так как $v_1, \dots, v_m$ --- линейно независимы, то $\dim V^{\perp} = n - \rk A = n - m = n - \dim V$. 
\end{proof}
\begin{lemma}
Пусть $V$ --- подпространство в $\mathbb{R}^n$. Тогда $\left(V^{\perp}\right)^{\perp} = V$
\end{lemma}
\begin{proof}
Пусть $x \in V$, тогда $\langle \vec{x},\vec{y} \rangle = 0\; \forall y \in V^{\perp}$, а значит $x \in \left(V^{\perp}\right)^{\perp}$ просто по определению. Но тогда $V \subseteq \left(V^{\perp}\right)^{\perp}$. Отсюда $\dim \left(V^{\perp}\right)^{\perp} = n - (n - \dim V) = \dim V$, что и означает равенство $\left(V^{\perp}\right)^{\perp}$ и $V$.
\end{proof}
\begin{base_44-cons}
Всякое подпространство в $\mathbb \bbR^n$ является множеством решением некоторой СЛУ.
\end{base_44-cons}
\begin{proof}
Пусть $V$ --- подпространство в $\mathbb{R}^n$. По предыдущей лемме имеем, что $V = \left( V^{\perp} \right)^{\perp}$. Пусть $\{v_1, \ldots, v_m\}$ --- базис в $V^{\perp}$. Рассмотрим матрицу $A \in \Mat_{m \times n} $, где $A_{(i)} = v_i^T$. Тогда $V$ есть множество решений СЛУ $A\vec{x} = \vec{0}$.
\end{proof}

% 54 - Хачиянц Алексей
\subsection{Линейные многообразия в $\mathbb{R}^n$ как сдвиги подпространств.\\ Размерность линейного многообразия.}
\textit{Линейным многообразием в $\mathbb{R}^n$} называется множество всех решений какой-то СЛУ.

\begin{linear_manifold_1}
Множество $S \in \mathbb{R}^n$ --- линейное многообразие тогда и только тогда, когда $S = \vec v_0 + V$, где $\vec v_0 \in \mathbb{R}^n$, а $V$ --- подпространство в $\mathbb{R}^n$. Иными словами,
линейное многообразие есть сдвиг некоего подпространства, и наоборот.
\end{linear_manifold_1}

\begin{proof} Докажем теорему в обе стороны:
\begin{itemize}

\item[{$[\Rightarrow]$}] 
Пусть $S \in \mathbb{R}^n$ --- непустое линейное многообразие, являющееся множеством решений СЛУ $A\vec x = \vec b$, и $L$ --- множество решений однородной СЛУ $A \vec x = \vec 0$. Как было доказано ранее, $L$ --- подпространство в $\mathbb{R}^n$, из чего следует, что $S = \vec x_p + L$, где $x_p$ --- какое-то частное решение СЛУ $A\vec x = \vec b$.

\item[{$[\Leftarrow]$}]
Пусть $S = \vec v_0 + V$ для некоторых $\vec v_0 \in \mathbb{R}^n$ и подпространства $V \in \mathbb{R}^n$. Так как $V$ --- подпространство, то $V$ есть множество решений некоторой однородной СЛУ $A\vec x = \vec 0$, тогда $v_0$ --- частное решение СЛУ $A\vec x = A\vec v_0$ (правая часть $\vec b = A\vec v_0$). Значит, $S$ --- множество решений СЛУ $A\vec x = A\vec v_0$, то есть $S$ является линейным многообразием.
\end{itemize}
\end{proof}

\textit{Размерность линейного многообразия $S = \vec v_0 + V$ из $\mathbb{R}^n$} --- число $\dim S = \dim V$.

\begin{proposal}
Пусть $S$ --- непустое линейное многообразие в $\mathbb{R}^n$, являющееся множеством решений СЛУ $A\vec x = \vec b$. Тогда $\dim S = n - \rk A$.
\end{proposal}
\begin{proof}
Пусть $L$ --- множество решений однородной СЛУ $A\vec x = \vec 0$. Из вышедоказанной теоремы следует, что размерность линейного многообразия есть размерность подпространства, его образующего: $\dim{S} = \dim{L}$. Тогда $S = \vec x_p + L \Rightarrow \dim S = \dim L = n - \rk A$.
\end{proof}

\end{document}
